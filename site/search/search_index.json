{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Lumi's Blog!!!","text":"<p> This is a personal web page by Lumi. On this page, I will share interesting things I encountered in my everyday life, things I do, and sparks during my learning career. I hope that you can all feel my happiness, and see that I am actually growing. <p> If you have Any advices or feedbacks, feel free to pull up an issue in the GitHub repository page, or email(12112618@mail.sustech.edu.cn) me."},{"location":"testing/","title":"Testing","text":"<p>The Pearson correlation coefficient (r) is calculated using the following formula:</p> <p>r = (\u03a3(x_i - x\u0304)(y_i - \u0233)) / \u221a((\u03a3(x_i - x\u0304)^2)(\u03a3(y_i - \u0233)^2))</p> <p>Where: - <code>r</code> is the correlation coefficient - <code>x_i</code> and <code>y_i</code> are the individual data points for variables x and y, respectively - <code>x\u0304</code> and <code>\u0233</code> are the means of the x and y variables, respectively - <code>\u03a3</code> denotes the sum of the values</p> <p>The value of <code>r</code> ranges from -1 to 1, where: - <code>r = 1</code> indicates a perfect positive linear relationship - <code>r = -1</code> indicates a perfect negative linear relationship - <code>r = 0</code> indicates no linear relationship</p>"},{"location":"About/","title":"Welcome to Lumi's Blog!!!","text":"<p>This is a personal web page by Lumi. On this page, I will share interesting things I encountered in my everyday life, things I do, and sparks during my learning career. I hope that you can all feel my happiness, and see that I am actually growing. <p> If you have Any advices or feedbacks, feel free to pull up an issue in the GitHub repository page, or email(12112618@mail.sustech.edu.cn) me."},{"location":"About/SelfIntro/SelfIntro/","title":"About Me","text":"<p> My name is Lumi, which comes from my Chinese name Zhang Luming. I am from Guangzhou, China.  <p></p>","tags":["Me","Life"]},{"location":"About/SelfIntro/SelfIntro/#studying-experiences","title":"Studying Experiences <p>I am a undegraduate majoring in bioinformatics in SUSTech, I am also very proud to be a member of Shuren College. My school is very beautiful and the teachers here are very nice. I enjoy learning in such a wonderful school!","text":"","tags":["Me","Life"]},{"location":"About/SelfIntro/SelfIntro/#hobbies","title":"Hobbies <p>I consider myself as a very funny person and my hobbies change very quickly. But learning is something I always like and I'm always eager to learn more. That's why you will find a lot of learning related posts in my blog. <p> My other hobbies include <ul> <li>  \ud83e\udd3a Fencing &amp; \ud83d\udea3 Rowing <li>  \ud83d\udcbb Trying all sorts of things involving Computers <li>  \ud83c\udfae Playing games <li>  \ud83d\udcd6 Reading all kinds of books <li>  \ud83c\udf55 Eating delicious food <li> \ud83c\udfac Watching movies  <p> AND a lot more!","text":"","tags":["Me","Life"]},{"location":"Bioinformatics/","title":"Bioinformatics is not quantum mechanics","text":"<p>Well, my major is bioinformatics, and the more I learn it, the more I find myself loving it. I don't think I need to say anything more! <p> Click on the left side to learn about the details."},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/","title":"Tools in ATAC-Seq","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#atac-seq-pipeline","title":"ATAC-Seq pipeline <p>  In the introduction (which I didn't write at 28 of Sep), we introduced the basic workflow of ATAC-Seq. In this note, I will introduce each step carefully with codes.","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#pre-analysis-quality-control-alignment","title":"Pre-analysis: Quality Control &amp; Alignment","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#fastp","title":"fastp <p> We also introduced fastp in RNA-Seq, it's just a fast and all in one quality check machine. It can simultaneously check the quality and trim the reads. <pre><code>fastp -a CTGTCTCTTATA --detect_adapter_for_pe -w 12 --length_required 20 -q 30 -i $fq1 -I $fq2 -o trim/${sampled}_1.fq.gz -0 trim/${sampleid}_2.fq.gz -h trim/${sampleid}_fastp.html\n</code></pre> <ul> <li> <p> -a, --adapter_sequence           the adapter for read1. For SE data, if not specified, the adapter will be auto-detected. For PE data, this is used if R1/R2 are found not overlapped. (string [=auto])  <li> <p> --detect_adapter_for_pe      Turns on the auto detection of adapters for pair end sequencing data. (Automatically turned on for single end data)  <li> <p> --length_required     Reads shorter than length_required will be discarded, default is 15.   <p>  For more commands, type <code>fastp -help</code> in terminal or look here. <p>  Ex. For loops in shell <pre><code>    for ((i=0; i&lt;=10; i++)); do          \n        echo \"/$i\"; \n    done\n</code></pre>","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#bowtie2","title":"Bowtie2 <p> Bowtie2 is another sequence alignment tool. Similar to HISAT2 (in fact they are developed by the same bunch of people, interesting). <pre><code>bowtie2 -x ~/reference/bowtie2/xenTro10 -1 trim/${sampleid}_1.fq.gz -2 trim/${sampleid}_2.fq.gz -p 12 -X 2000 | samtools view -bS - -@ 12 &gt; mapping/${sampleid}.bam\n</code></pre> <p>  Sometimes we need to filter low quality alignments, or alignments with problems (marked in the FLAG part of SAM files). In TianChi's pipeline, he used a python program to filter these reads, but I think tools in samtools can fulfill the needs. Nevertheless, here's the code. <pre><code>/home/bio-ligp/miniconda3/envs/py2/bin/python ~/bin/filter_bam.py -i mapping/${sampleid}.bam -o mapping/${sampleid}.filt.bam\n</code></pre>","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#sambamba","title":"Sambamba <p> A samtools like program to process sam and bam files. But sambamba can process sam and bam files quicker, which is very interesting. <pre><code>sambamba sort --sort-picard -m 8G --tmpdir=tmp -t 12 mapping/${sampleid}.filt.bam -o mapping/${sampleid}.sort.bam\n\nsambamba markdup -r -t 12 --tmpdir=tmp mapping/${sampleid}.sort.bam mapping/${sampleid}.dup.bam\n</code></pre> <p>  Sambamba sort: :  --sort-picard sort by query name like in picard     -m approximate total memory limit for all threads (by default 2GB)     --tmpdir=TMPDIR directory for storing intermediate files; default is system directory for temporary files     -t number of threads     -o output file <p>  Sambamba markdup: :  -r remove duplicates instead of just marking them     -t number of threads to use     --tmpdir=TMPDIR directory for storing intermediate files; default is system directory for temporary files <p> We also need to sort the bam file again with samtools. Because the sambamba sorting sort the bam file according to picard. <pre><code>samtools sort -@ 12 mapping/$sampleid.dup.bam &gt; mapping/$sampleid.dup.sort.bam\n</code></pre>","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#post-alginment-quality-control","title":"Post-alginment: Quality Control","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#get_tlen","title":"get_tlen <p>  Getting the fragment length. <pre><code>python ~/bin/get_tlen.py -i mapping/$sampleid.dup.sort.bam &gt; mapping/$sampleid.dup.sort.bam.tlen.txt\n</code></pre>","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#atacseqqc","title":"ATACseqQC <p>  An R package that can perform ATACseqQC. Requires the bam file.","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#peak-calling","title":"Peak Calling","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#macs2","title":"MACS2 <p>  MACS2 can differentiate the statistically significant peaks of reads from others and generate a peak file. <pre><code>macs2 callpeak -t mapping/$sampleid.dup.sort.bam -g 1.435e9 --keep-dup all --outdir peaks -n $sampleid -q 0.05 --slocal 10000 --nomodel --nolambda -B --SPMR\n</code></pre> <p> -t ChIP-seq treatment file. If multiple files are given as '-t A B C', then they will all be read and pooled together. REQUIRED. <p> -g The effective genome size. It can be 1.0e+9 or 1000000000, or shortcuts:'hs' for human (2.7e9), 'mm' for mouse (1.87e9), 'ce' for C. elegans (9e7) and 'dm' for fruitfly (1.2e8), Default:hs <p> --keep-dup It controls the behavior towards duplicate tags at the exact same location -- the same coordination and the samestrand. The 'auto' option makes MACS calculate the maximum tags at the exact same location based on binomaldistribution using 1e-5 as pvalue cutoff; and the 'all' option keeps every tags. If an integer is given, at mostthis number of tags will be kept at the same location. Note, if you've used samtools or picard to flag reads as'PCR/Optical duplicate' in bit 1024, MACS2 will still read them although the reads may be decided by MACS2 asduplicate later. If you plan to rely on samtools/picard/any other tool to filter duplicates, please remove thoseduplicate reads and save a new alignment file then ask MACS2 to keep all by '--keep-dup all'. The default is tokeep one tag at the same location. Default: 1 <p> --outdir If specified all output files will be written to that directory. Default: the current working directory <p> -n NAME Experiment name, which will be used to generate output file names. DEFAULT: \"NA\"  <p> -q Minimum FDR (q-value) cutoff for peak detection. DEFAULT: 0.05. -q, and -p are mutually exclusive. <p> --slocalThe small nearby region in basepairs to calculate dynamic lambda. This is used to capture the bias near the peak summit region. Invalid if there is no control data. If you set this to 0, MACS will skip slocal lambda calculation. Note that MACS will always perform a d-size local lambda calculation while the control data is available. The final local bias would be the maximum of the lambda value from d, slocal, and llocal size windows. While control is not available, d and slocal lambda won't be considered. DEFAULT: 1000 <p> --nomodel Whether or not to build the shifting model. If True, MACS will not build model. by default it means shifting size = 100, try to set extsize to change it. It's highly recommended that while you have many datasets to process and you plan to compare different conditions, aka differential calling, use both 'nomodel' and 'extsize' to make signal files from different datasets comparable. DEFAULT: False <p> --nolambdaIf True, MACS will use fixed background lambda as local lambda for every peak region. Normally, MACS calculates a dynamic local lambda to reflect the local bias due to the potential chromatin accessibility. <p> -B Whether or not to save extended fragment pileup, and local lambda tracks (two files) at every bp into a bedGraph file. DEFAULT: False <p> --SPMR If True, MACS will SAVE signal per million reads for fragment pileup profiles. It won't interfere with computing pvalue/qvalue during peak calling, since internally MACS2 keeps using the raw pileup and scaling factors between larger and smaller dataset to calculate statistics measurements. If you plan to use the signal output in bedGraph to call peaks using bdgcmp and bdgpeakcall, you shouldn't use this option because you will end up with different results. However, this option is recommended for displaying normalized pileup tracks across many datasets. Require -B to be set. Default: False","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#bamcoverage","title":"bamCoverage <p> Convert bam reads into bigwig files. Which are made to calculate the \"score\" of each gene. That is to say, how many reads are mapped with a certain gene of the genome. Of course, because the thing is going into the igv, the bam files need to be indexed. <pre><code>samtools index -@ 12 mapping/$sampleid.dup.sort.bam\nbamCoverage -b mapping/$sampleid.dup.sort.bam -p 12 --normalizeUsing CPM --binSize 5 -o bigwig/$sampleid.ATAC.bw\n</code></pre>  <p>  binSize is actually a very important parameter that will influence plotting later. It means that five nucleotide reads are combined to calculate one score, rather than computing it one by one, which is time and storage consuming. See here for more info.","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#plotting-the-heatmap","title":"Plotting the Heatmap <p> After getting the bigwig file, we can draw heatmaps using the computeMatrix tool and plotHeatmap tool from deeptools.","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#computematrix","title":"computeMatrix <p> ComputeMatrix tool compares different peaks with the bigwig file to get where the location of the peaks. <p> Reference Point  Because of my spupidity, I actually stuck the summit bed file (with sequence length 1) into computeMatrix, and sadly the other method of scale-region didn't work. So we switched to reference point (because in principle, a summit can also used to draw a heatmap). It did finish calculating the matrix, but I don't think the result is correct since instead of using the middle of the peak sequence, we only used the summit as the middle, which is not the case in every peak.  However, after careful consideration, this is actually what we need to use during ATAC-seq  Yeah, I'm back on the right track. We actually need to use the summits bed file and reference point to draw our ATAC-Seq heatmap. What we cared is the amount of reads in proximity to our peak (i.e. our summit), so using the summit as the middle point is completely right. <pre><code>computeMatrix reference-point -S /data/bio-zhanglm/xenopus/09_Bigwig/st9-ATAC-${i}.bw \\\n        -R /data/bio-zhanglm/xenopus/08_Peak/st9-${i}_summits.bed \\\n        -o /data/bio-zhanglm/xenopus/10_Graph/st9-${i}-matrix.gz -a 1500 -b 1500;\n</code></pre>","text":""},{"location":"Bioinformatics/ATAC-Seq/ATAC-Seq_tools/#plotheatmap","title":"plotHeatmap <p> With the data you got from computeMatrix, you can plot a heatmap showing the amount of reads on either end of your peak. <pre><code>plotHeatmap -m /data/bio-zhanglm/xenopus/10_Graph/st9-2-matrix.gz -o /data/bio-zhanglm/xenopus/10_Graph/st9-ATAC-Heatmap-2.png\n</code></pre> <p> Compared to earlier steps, this step is really as easy as hell.","text":""},{"location":"Bioinformatics/Nanopore/Learning/","title":"Learning","text":""},{"location":"Bioinformatics/Nanopore/Learning/#_1","title":"Learning","text":""},{"location":"Bioinformatics/R/DESeq/","title":"R and DESeq2","text":"<p> DESeq2 is a very special R package made for performing differential expression analysis on your sequence, especially when you are tring to define differences between multiple biological conditions (e.g. treated, untreated). <p>  Most of my overall knowledge comes from surfing the internet, and I found: <ul> <li> <p> A wonderful girl teaching DESeq2. Her channel is so rich in knowledge, everyone, subscribe now!!! <li> <p> Another youtuber who teaches all the different plots in both R and python. <li> <p> The original manual for DESeq2. <li> <p> Another DESeq2 tutorial made very thoroughly and clear, I love it! <li> <p> The DESeq2 tutorial made by Griffith lab of Washington University. Which is surprisingly detailed when it comes to plotting."},{"location":"Bioinformatics/R/DESeq/#getting-ready-for-deseq2","title":"Getting Ready for DESeq2 <p>  In our RNA-seq workflow, we used cuffdiff to get a general differential expression result, from it, you can easily see which genes are expressed more, which are suppressed, in other words, which genes have a significant count difference from the other genes. <p> But when we come to the real biological experiments and analysis, we usually want to know more about our gene and about our test subjects. We might even want to draw fancy pictures to convey our ideas. That's when our rather old tool cuffdiff doesn't shine.  <p> DESeq2 basically work nearly the same as cuffdiff (although the algorithms might be a bit different), but the final result we are looking for are bascially the same. The log2(foldchanges) and p_values and all those things. So how does it work?","text":""},{"location":"Bioinformatics/R/DESeq/#getting-the-matrix","title":"Getting the Matrix <p> First we need the count matrix from our data. We need an old friend from our RNA-seq workflow - featureCounts.  <pre><code>featureCounts [options] -a &lt;annotation_file&gt; -o &lt;output_file&gt; input_file1 [input_file2] ... \n</code></pre> <p> By typing this command into the terminal, feature counts will automatically map all the counts to the genes in your annotation file. Thus providing you with a matrix of counts for specific genes. We only need the counts for each matrix, so we can cut the matrix in the command line or in R. We might also want to remove some data with very low counts, since they are not very significant, and we can do that also in the command line or in R.","text":""},{"location":"Bioinformatics/R/DESeq/#input-the-matrix-into-r","title":"Input the Matrix into R <p> The next step is to get your matrix into R and prepare it for DESeq2. The code I used was this, and I found it pretty elegant. <pre><code># input data \ninput_data &lt;- read.table(\"deseq2_input.txt\",header = T, row.names = 1)\n\n\n# preperation \ninput_data &lt;- as.matrix(input_data)\ncondition &lt;- factor(c(rep(\"ctrl\",4), rep(\"DDX6KO\",4)))\ncoldata &lt;- data.frame(row.names = colnames(input_data),condition)\n</code></pre> <p> First we input the data into the variable input_data by the R function read.table(). You can always get help in R by just typing <code>?functionName()</code> in the R console. So in the read.table() function, we set the first row as our header with <code>header = T</code>. <code>row.names = 1</code> indicates that the first column of each row gives the name of the first row. <p> Then, we prepare the raw data so that it fits the requirements of DESeq2. Apart from the original data matrix from your sequencing results, DESeq2 also requires another matrix containing informations on the columns of our data (in other words, the names and types of your contol and experiment groups). So the <code>as.matrix</code> turns the data into a matrix fit for calculation. <code>condition</code> stores a factor of two (it can be more than two). <code>coldata &lt;- data.frame()</code> gives DESeq2 the column data it needs.","text":""},{"location":"Bioinformatics/R/DESeq/#construct-the-deseq-dataset","title":"Construct the DESeq Dataset <p> Then we use our data to construct a DESeq Dataset from our matrix (in this case, <code>input_data</code>). <pre><code>library(DESeq2)\n# construct a deseq input data matrix\ndds &lt;- DESeqDataSetFromMatrix(countData = input_data, colData = coldata, design = ~condition)\n\ndim(dds)\ndim(dds[rowSums(counts(dds)) &gt; 5,])\ndds &lt;- dds[rowSums(counts(dds)) &gt; 5,]\n</code></pre> <p> We first need to import the DESeq2 library (package) (of course).  <p> Then, we use the function <code>DESeqDataSetFromMatrix()</code> from DESeq2 package to input our raw data. <code>colData</code> is the matrix we made earlier containing the data for row names and types and all those stuff. <code>design = ~condtion</code> means that the data is designed by the factor <code>condition</code> in the <code>colData</code> variable. In designed, I mean that the DESeq process will perform the differential expression analysis based on the different conditions of the experiments. The conditions are also set manually. You can add another column in the <code>colData</code> matrix called <code>time</code>, and set the design to <code>design = ~condition + time</code>, DESeq will restrain the effects of condition and focus on the time factor. For more information, see this blog on BioStars. <p>  We can check the dimensions of dds using <code>dim(dds)</code>. We could remove the results when the gene's counts are less than 5 in total, by reassigning the value of dds to <code>dds[rowSums(counts(dds)) &gt; 5,]</code>. Thus we got our DESeq Dataset, named <code>dds</code>, and we can happily perform differential expression analysis on it!~","text":""},{"location":"Bioinformatics/R/DESeq/#finally-the-deseq-analysis","title":"Finally, the DESeq analysis <p> The actual analysis part is really easy to understand, and doesn't require a lot of code of brain. <pre><code># perform the differential expression analysis\ndds &lt;- DESeq(dds)\nres &lt;- results(dds)\n</code></pre> <p> Just type these words and everything will be done in the background thanks to our lovely DESeq2 developers. The deeper truth behind all the analysis is much more complex, and I don't think I fully understand it. I will leave a link here to the lovely Indian girl's video, and I might make another whole chapter just talking about how it works. But for us who are just using it and only cares about the final output data, these two lines of code is enough.","text":""},{"location":"Bioinformatics/R/DESeq/#plot-your-data","title":"Plot Your Data <p> After we obtained our data from DESeq, we need to know how to show everyone else in a clear and fasionable way, what is happening in our experiments. That's where our beautiful plots come. A wide variaty of plots can be used to express our data, and it's best if we know how to draw each one of them, and more importantly, the essence behind every plot. <p> The knowledge of the plotting part mainly comes from the Griffith lab website, which is here. There might be some websites helpful for individual plotting, I will list each of the websites in their own part.","text":""},{"location":"Bioinformatics/R/DESeq/#the-ma-plot","title":"The MA plot <p> MAplots are plots that can display the difference of measurements between two sets of data. <p> DESeq2 have it's own MAplotting function. Which is simply: <pre><code>plotMA(res, ylim = c(-3,3))\n</code></pre> <p></p> <p> But this MA plot only have two colours, and is rather lame. With ggplot's function geom_point, we could make a similar MA plot. <pre><code>library(ggplot2)\ndeseq2ResDF &lt;- as.data.frame(res) ## convert the result file into a data frame\ndeseq2ResDF$significant &lt;- ifelse(deseq2ResDF$padj &lt; .1, \"Significant\", NA) ## a new column for significance\n\nggplot(deseq2ResDF, aes(baseMean, log2FoldChange, colour = padj)) + \n  geom_point(size=0.5) + scale_y_continuous(limits=c(-3, 3)) + \n  scale_x_log10() + geom_hline(yintercept = 0, colour=\"darkorchid4\", size=1, linetype=\"longdash\") + \n  labs(x=\"mean of normalized counts\", y=\"log fold change\") + \n  theme_bw() + geom_density_2d(colour=\"black\", size=0.25) +\n  scale_colour_gradient( high = \"#f8ff2b\", low = \"#ff2b2b\", space = \"Lab\", na.value = \"grey50\", guide = \"colourbar\", aesthetics = \"colour\")\n</code></pre> <p></p> <p>  By adding a series of constraints, we can make the geom_point look just like our MAplot. But first, we need to input our DESeq Data as a dataframe, and than add a new column called significant to the end of the dataframe. Remember to add <code>scale_x_log10</code> or else it will display the original counts, which are massive.","text":""},{"location":"Bioinformatics/R/DESeq/#heatmap","title":"Heatmap <p> The heatmap knowledge comes from this video. <p> Heatmaps are often used to show the difference between two groups of data, for example the experiment and the control. We can use the data we got from DESeq to plot a wonderful heatmap. <p></p> <p> A fantastic heatmap tutorial can be found here.  <pre><code>library(DESeq2)\nlibrary(ComplexHeatmap)\nlibrary(RColorBrewer)\nlibrary(circlize)\n</code></pre> <p> Four libraries are used to draw this kind of heatmap.  <pre><code>dds_sig &lt;- subset(deseq2ResDF, significant == \"Significant\")\ndds_sig &lt;- dds_sig[(dds_sig$baseMean &gt; 50) &amp; (abs(dds_sig$log2FoldChange) &gt; 2),]\ndds_sig &lt;- dds_sig[order(dds_sig$log2FoldChange, decreasing = T),]  \n</code></pre> <p> We first make a subset of our result matrix based on the significance (which comes from the padj number, usually padj &lt;.1 can be considered significant). Then we filter this data by deleting the rows that have very small baseMean number (which means it's probably background noise), and choose those genes that have the largest foldchange (which are the most significant genes). Then we order our data so that the genes that have the largest change are at the first and last rows of the matrix. <pre><code>rlog_out &lt;- rlog(dds, blind = F)\nmat &lt;- assay(rlog_out)[rownames(dds_sig),rownames(coldata)]\ncolnames(mat) &lt;- rownames(coldata)\nbase_mean &lt;- rowMeans(mat)\n</code></pre> <p> Then we perform the rlog function on the DESeq Dataset to calculate the Z-score for the genes. Because the rlog_out is another dataset, we transform it into another matrix and set the column and row name of the matrix. <pre><code>mat_scaled &lt;- t(apply(mat, 1, scale))\ncolnames(mat_scaled) &lt;- colnames(mat)\n</code></pre> <p>  Then we scale the matrix, which I guess is similar to the SVD decomposition, to get their influence factors on the difference. In our case, the scaling is more like normalizing the data of each row of mat, thus setting a global standard to express the difference between each group. Then set the names of our new matrix, and then we are done.  <pre><code>rows_keep &lt;- c(seq(1:25), seq((nrow(mat_scaled) - 25), nrow(mat_scaled)))\n\nl2_val &lt;- as.matrix(dds_sig[rows_keep,]$log2FoldChange)\ncolnames(l2_val) &lt;- \"logFC\"\n\nmean_val &lt;- as.matrix(dds_sig[rows_keep,]$baseMean)\ncolnames(mean_val) &lt;- \"AveExpr\"\n</code></pre> <p> Then we chose the 50 genes that have the largest and smallest foldchange to plot. We also want to plot their log2FoldChange value and baseMean value, so we extract them from the original sorted data (not from the normalized matrix). <pre><code>col_logFC &lt;- colorRamp2(c(min(l2_val),0,max(l2_val)),c(\"blue\",\"white\",\"red\"))\ncol_AveExpr &lt;- colorRamp2(c(quantile(mean_val)[1], quantile(mean_val)[4]), c(\"white\",\"red\"))\n</code></pre> <p> We set the colour for our log(FoldChange) and baseMean sub-heatmap so that it matches our main matrix. <pre><code>h1 &lt;- Heatmap(mat_scaled[rows_keep,], cluster_columns = T, cluster_rows = F,\n              column_labels = colnames(mat_scaled), name = \"Z-score\")\n\nha &lt;- HeatmapAnnotation(summary = anno_summary(gp = gpar(fill = 2), height = unit(2, \"cm\")))\nh2 &lt;- Heatmap(l2_val, row_labels = rownames(dds_sig[rows_keep,]),\n              cluster_rows = F, name = \"LogFC\", top_annotation = ha,\n              col = col_logFC, \n              cell_fun = function(j, i, x, y, w, h, col){\n                grid.text(round(l2_val[ i, j], 2), x, y)\n              })\n\nh3 &lt;- ComplexHeatmap::Heatmap(mean_val, row_labels = rownames(dds_sig[rows_keep,]),\n              cluster_rows = F, name = \"AveExpr\", \n              col = col_AveExpr, \n              cell_fun = function(j,i,x,y,w,h,col){\n                grid.text(round(mean_val[ i, j], 2), x, y)\n              })\n\nh &lt;- h1 + h2 + h3\nh\n</code></pre> <p> Then we finally plot the heatmap. <code>h1</code> is the main heatmap which demonstrates the expression difference of each gene in different group. <code>h2</code> and <code>ha</code> are bound together, <code>h2</code> shows the fold change of each individual gene, and <code>ha</code> is a small heatmap annotation showing the range of log(foldChange). At last <code>h3</code> is the baseMean value heatmap. We then combine all three graphs together, and get our final complex heatmap.","text":""},{"location":"Bioinformatics/R/DESeq/#gene-ontology","title":"Gene Ontology <p> The gene ontology knowledge comes from this video. <pre><code># BiocManager::install(\"AnnotationDbi\")\n# BiocManager::install\nlibrary(clusterProfiler)\nlibrary(AnnotationDbi)\nlibrary(org.Hs.eg.db)\n</code></pre> <p> The three R packages we need to plot a gene ontology mapping. <pre><code>gene_up &lt;- rownames(dds_sig[dds_sig$log2FoldChange &gt; 1.5,])\n</code></pre> <p> Filter out the genes that have the log2FoldChange bigger than 1.5. Which are the most effected pathways. <pre><code>GO_up &lt;- enrichGO(gene = gene_up, OrgDb = \"org.Hs.eg.db\", keyType = \"SYMBOL\", ont = \"BP\")\n</code></pre> <p> We then perform the gene ontology analysis on our genes, the gene ontology package can match each gene to their relating pathway. Our gene is a human gene, so we use the human reference, thus the <code>org.Hs.eg.db</code> (if we need the mouse reference, we can use <code>org.Mm.eg.db</code>). <code>keyType</code> might be ENSEMBL or SYMBOL, depending on the type of your gene's name. For <code>ont</code> we usually choose BP. <p></p> <pre><code>up_plot &lt;- plot(barplot(GO_up, showCategory = 20))\nup_plot\n</code></pre> <p> Then we plot the first 20 pathways, and thus show what pathways our experiment influence most. The graph looks something like this. We can make it look more beautiful by adjusting different variables. <p></p>","text":""},{"location":"Bioinformatics/R/DESeq/#volcano-plot","title":"Volcano Plot <p> The volcano plot knowledge comes from this video. <p> Volcano Plots can show you the differentially expressed genes, using the EnhancedVolcano library, we can easily plot amazing volcano plots easily. <pre><code>res_vol &lt;- as.data.frame(res0.01[res0.01$baseMean &gt; 200, ])\n\nlibrary(EnhancedVolcano)\n\nsel_tab &lt;- c(\"DDX6\",\"IFI27\",\"HPGD\",\"GPI\",\"PRF1\")\n\nEnhancedVolcano(res_vol, x = \"log2FoldChange\", y = \"padj\", lab = rownames(res_vol),\n                selectLab = sel_tab, title = \"DDX6KO\", subtitle = \"\")\n</code></pre> <p> First we filter the low count data, and pass it into a dataframe. We could plot out the selected gene tabs using the variable <code>sel_tab</code>. <p></p>","text":""},{"location":"Bioinformatics/RNA-seq/Files/","title":"Files involved in RNA-seq","text":"<p>Here, I learnt about all the different files that may come up during a NGS analysis. All the knowledge comes from: <p>General: <ul> <li> https://learn.gencore.bio.nyu.edu A very  useful website teaching about NGS analysis. <p>FASTA &amp; FASTQ: <ul> <li> https://support.illumina.com/bulletins/2016/04/fastq-files-explained.html <li> http://www.biotrainee.com/thread-2703-1-2.html <li> https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=BlastHelp <p>SAM/BAM/CRAM: <ul> <li> https://samtools.github.io/hts-specs/SAMv1.pdf <p>GFF/GTF: <ul> <li> https://useast.ensembl.org/info/website/upload/gff.html <li> https://en.wikipedia.org/wiki/Gene_transfer_format <p> Unix <ul> <li> http://korflab.ucdavis.edu/Unix_and_Perl/current.html"},{"location":"Bioinformatics/RNA-seq/Files/#fastq-and-fasta","title":"FASTQ and FASTA <p>The first section is about FASTQ and FASTA files.","text":""},{"location":"Bioinformatics/RNA-seq/Files/#fastq","title":"FASTQ <p> FASTQ files contains four lines including: <ol> <li>The sequence Identifier with information about the sequencing run and the cluster. <li>The sequence read. <li>A separator, which is simply a plus (+) sign, but sometimes might also be a (-) sign. <li>The quality scores. Using ASCII characters to represent the numerical quality of the scores.  <p></p>","text":""},{"location":"Bioinformatics/RNA-seq/Files/#quality-scores","title":"Quality Scores <p> Quality scores are a way to assign confidence to a particular base within a read. The code is related to the ASCII table and each letter is related to a different Q score. <p> The quality score Q is related to the probability of incorrect corresponding base call. <p></p> <p> By matching the ASCII table characters to their Q code under certain protocals, we can easily (?) know the quality of the specific gene. <p></p>","text":""},{"location":"Bioinformatics/RNA-seq/Files/#fasta","title":"FASTA <p>FASTA format is a basic format for repoting a sequence whether it's a nucleic acid or amino acid. Made up by two parts: <ul> <li>A sequence header which starts with a '&gt;' and contaisn the sequence description. <li>The sequence itself (containing no space within).<pre><code>&gt;P01013 GENE X PROTEIN (OVALBUMIN-RELATED)\nQIKDLLVSSSTDLDTTLVLVNAIYFKGMWKTAFNAEDTREMPFHVTKQESKPVQMMCMNNSFNVATLPAE\nKMKILELPFASGDLSMLVLLPDEVSDLERIEKTINFEKLTEWTNPNTMEKRRVKVYLPQMKIEEKYNLTS\nVLMALGMTDLFIPSANLTGISSAESLKISQAVHGAFMELSEDGIEMAGSTGVIEDIKHSPESEQFRADHP\nFLFLIKHNPTNTIVYFGRYWSP\n</code></pre>","text":""},{"location":"Bioinformatics/RNA-seq/Files/#sambamcram-format","title":"SAM/BAM/CRAM Format","text":""},{"location":"Bioinformatics/RNA-seq/Files/#sam","title":"SAM <p>The Sequence Alignment/Map (SAM) format is the most basic and most human readable format of the three. It consists of a header, and a row for every read in your dataset, and 11 tab-delimited fields describing that read.","text":""},{"location":"Bioinformatics/RNA-seq/Files/#sam-header","title":"SAM Header <p>The SAM header varies in size, but header lines start with '@', while alignment lines do not. You can customize the header when you generate the SAM file, add the information you decided to add. The full list of header fields are found below. '*' means that this tag is required; e.g., every <code>@SQ</code> header line must contain <code>SN</code> and <code>LN</code> fields. <p></p> <p></p>","text":""},{"location":"Bioinformatics/RNA-seq/Files/#fields-descriptions","title":"Fields Descriptions <p>Every row contains 11 mandatory fields, which are:  <p></p> <p> Bitwise Flag is a lookup code to explain certain features about the particular read (exact same concept as Linux permission codes!). It tells you whether the read aligned, is marked a PCR duplicate, if it\u2019s mate aligned, etc. and any combination of the available tags, seen below: <p></p> <p>Sometimes it might be a bit hard to explain the integers of the Bitwise Flag, you can go on Picard to get a quick analysis. <p> Map Q (Mapping Quality) reveals how well the read are aligned to the reference. Different algorithm might lead to different scores, but generally, the greater the number, the better the alignment. <p> CIGAR String is a special string that can tell you the alignment information of the whole sequence. <p></p> <p></p>","text":""},{"location":"Bioinformatics/RNA-seq/Files/#bam","title":"BAM <p> BAM format has literally the same content as the SAM file, except it's in Binary format. Thus it's not legible to human but is smaller and faster to read for a computer. <p> Tools like Samtools, Picard Tools and IGV are required to make sence of BAM files.","text":""},{"location":"Bioinformatics/RNA-seq/Files/#cram","title":"CRAM <p> This is a relatively new format that is very similar to BAM as it also retains the same information as SAM and is compressed, but it is much smarter in the way that it stores the information. It\u2019s very interesting and up and coming but is a bit beyond my level and not so relative to RNA-seq. To learn more about it, you can read this.","text":""},{"location":"Bioinformatics/RNA-seq/Files/#vcf-format","title":"VCF Format <p> Variant calling format is a tab-delimited text file (different from Virtual Card Format), it is used to describe single nucleotide variants (SNVs) as well as insertions, deletions and other sequence variations. It is limited to only show the variations not the genetic features. <ul> <li>Chromosome Name <li>Chromosome Position <li> <p>ID  <p>This is generally used to reference an annotated variant in dbSNP or other curate variant database.   <li> <p>Reference base(s)  <li>Alternate base(s) <li> <p>Variant quality  <p> Phred-scaled quality for the alternate base. Usually, a &gt;20 score is acceptable.   <li> <p>Filter  <p>Whether or not this has passed all filters \u2013 generally a QC measure in variant calling algorithms   <li> <p>Additional Information  <p>This is for additional information, generally describing the nature of the position/variants with respect to other data.    <p> For example vcf files, look at your own files during the class BIOS201, Genome, why are we different.","text":""},{"location":"Bioinformatics/RNA-seq/Files/#gff-and-gtf","title":"GFF and GTF <p> Gene transfer format (GTF) and General feaure format (GFF) are kinds of file format used to hold information about gene structure. <p> https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md","text":""},{"location":"Bioinformatics/RNA-seq/Files/#bed","title":"BED <p> The formal bed format description can be found here. <p> In shorter words, BED files allows an easy way to define the things you want to show in your track annotation (like a reference genome).","text":""},{"location":"Bioinformatics/RNA-seq/Files/#bed-graph","title":"Bed Graph <p> The detailed discription for bed graph is here, I think this file can be used to store the reads for each small sets of nucleotide on your chromosome after your sequencing.","text":""},{"location":"Bioinformatics/RNA-seq/Files/#bigwig","title":"BigWig <p> The BigWig files indicates the reads on a certain position. You can view it with igv, but also other applications and can turn it into a very beautiful graph. Requires further inquiry. The official BigWig file explaination can be found here.","text":""},{"location":"Bioinformatics/RNA-seq/RNA-seq/","title":"The Basic Workflow of RNA-seq","text":"<p>This note is about learning high-throughput RNA sequencing (RNA-seq), a standard technique for transcript discover and differential gene experession analysis in life science laboratories. <p>Source of my learning materials comes from the internet. I will list the websites and videos below. <ul> <li> https://www.bio-rad.com/en-hk/applications-technologies/rna-seq-workflow?ID=Q106ZUWDLBV5 <li> https://statquest.org/statquest-a-gentle-introduction-to-rna-seq/ <li> https://www.bilibili.com/video/BV1KJ411p7WN?p=1&amp;vd_source=bd89830c0df367ebc0f22c057e075b53","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#experiment-planning","title":"Experiment Planning <p>  Basic experiment steps include RNA extraction, RNA fragmentation (we have to break the RNAs into fragments because our reads are usually 300bp long in a short read sequencing), cDNA generation, library amplification, and sequencing on an NGS platform to get strings of continuous sequence data in \u201creads\u201d.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#reference-sequence","title":"Reference Sequence <p> Well-annotated genome like the human genome have reference transcipt sequences available for RNA-seq analysis. Otherwise, you might need to assemble the transcipts de novo and then map it onto the transcriptome","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#rna-seq-library-preparation","title":"RNA-Seq Library Preparation <p> Special Issues: <ul> <li> Reverse transcription of RNA into cDNA <li> Enrich, purify, and amplify the library prior to sequencing <li> Capture all types and sizes of RNA species  <p></p>","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#rna-enrichment","title":"RNA Enrichment <p> The step of RNA Enrichment is very important because almost 90% of the cell's RNA are the ribosome RNA, and we don't really want them for our sequencing. So we use certain measures to remove them and save the mRNAs or miRNAs (micro RNAs) we are interested in. The two methods used to achieve this in eukaryotic cells are rRNA removal and/or poly(A) selection of mRNA using oligo (dT) primers, which requires high-quality, high-abundance mRNA. Short RNAs like miRNA can be isolated by gel electrophoresis. <p></p>","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#strand-preservation","title":"Strand Preservation <p> Basic RNA-seq protocol is non-stranded, and it cannot distinguish the 1st and 2nd strand during cDNA generation, so the you cannot easily find the original mRNA. Stranded (also called directional) RNA-seq first accomplished this by using a modified dUTP nucleotides in place of dTTPs for second-strand cDNA synthesis (Parkhomchuk 2009). This allows for the second strand to be removed by digestion via uracil-N-glycosylase prior to PCR amplification.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#rna-seq-library-quantitation","title":"RNA-Seq Library Quantitation <p> The precise quantification of all next-generation sequencing (NGS) libraries is critical use of the NGS platforms. A good library quantitation provides information about the library quality and enables more efficient and consistent loading of libraries for sequencing runs as well as balancing of pooled library samples.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#single-ended-or-pair-end-reading","title":"Single-Ended or Pair-End Reading <p> Single-ended (SE) sequencing reads sequce fragments from only one direction, which may suffice for applications involving well-annotated genomes. But we prefer PE reads, where the fragments are sequenced from both directions. This approach is more costly, but provides the best coverage and is ideal for transcript discovery/quantitation, and identifying splicing junctions (Katz 2010). Long-read sequencing technologies can be used with PE reads to improve the specificity of mapping coding and long non-coding RNAs (\u0141abaj 2011).","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#depth-and-replicates","title":"Depth and Replicates <p> The optimal (best match) number of reads covering a specific region, or sequencing \u201cdepth\u201d, depends on the purpose of the study. In general, deeper sequencing provides better quantification, especially for low-abundance transcripts (Mortazavi 2008). However, the extra coverage in deep sequencing may also amplify noise or off-target reads (Tarazona 2011). The number of experimental replicates in an RNA-seq experiment depend on the inherent variability in the sequencing methodology or the biological system being used. In a gene expression profiling study it is critical that any measured differences in abundance are statistically significant.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#rna-sequence-analysis","title":"RNA Sequence Analysis <p> Common analysis process involves quality control, read alignment (mapping) with or without a reference genome, and other steps for transcript identification, transcript counting, and functional annotation. <p> In general, there are three steps to the bioinformatics analysis: primary, secondary, and tertiary analysis.  <p> Primary analysis is performed on the sequencer itself. For example, Illumina sequencing technology uses cluster generation and sequencing by synthesis chemistry to sequence millions or billions of clusters on a single flow cell, depending on the specific sequencing instrument. During sequencing itself, for each cluster, base calls are made and stored for every cycle of sequencing by software on the instrument. The base call data, which includes the confidence or quality of each base are stored in the form of individual base call (or BCL) files. When the sequencing is completed, the base calls in the BCL files are automatically converted into sequence data. This process is called BCL to FASTQ conversion. <p> Secondary analysis takes these FASTQ files to either perform an alignment (using a reference genome) or a de novo assembly (without a reference genome). For model organisms, where reference genomes are available, researcher can map individual reads from the FASTQ files to a reference. There are variety of sequence alignment tools available online.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#transcript-mapping","title":"Transcript Mapping <p>Mapping the reads to a reference sequence to identify and quantitate the expressed genes.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#reference-free-mapping","title":"Reference-Free Mapping <p> De novo construction is performed when the reference genome is incomplete or one does not exist. In this scenario, an assembly is constructed: short reads are assembled into larger contigs based on areas of sequence overlap, from which a full-length reference transcript is created for mapping. In order to generate adequate coverage for this purpose, PE strand-specific and long-read RNA-seq is preferred to short-read technologies. The software tools for this application include SOAPdenovo-Trans (Xie 2014), Oases (Schulz 2012), Trans-ABySS (Grabherr 2011) or Trinity (Haas 2013). While do novo assembly allows gene analysis from any system, it is less amenable to low-abundance transcripts or genes with complex splicing patterns (Au 2013; Steijger 2013). <p> I don't really understand the next part, so I will leave it copied from the website. <p> Assembly of millions of short sequencing reads into contigs is computationally difficult and requires addressing problems such as sequencing errors, coverage gaps, and the presence of splicing variants. One of two general approaches or algorithms are employed for assembly: overlap graphs and de Bruijn graphs. Early assemblers used pairwise overlaps between reads to extend contigs. These contigs are connected to create the reference. However, this approach is not practical when dealing with hundreds of millions of reads. Therefore, de novo transcriptome asssemblers use De Bruijn graphs, which are constructed and extended based upon k-mers, using a shorter subset of a read, where k is the length of the subsequence. A set of k-mers in a species\u2019 genome, in a genomic region, or in a class of sequences can be used as a signature of the underlying sequence. This makes the assembly process less computationally intensive. Most secondary analysis assembly tools use this De Bruijn graph method (Lin 2016; Chaisson 2008). <p></p> <p> Mapping short reads onto a De Bruin graph. Short sequence subsets, or k-mers, are assembled into contigs using an algorithm that considers each k-mer as a node on a graph then optimizes the graph by connecting edges at overlapping sequences and merging nonbranching paths to a single node to generate the shortest path length. Here, k=4 for example, but much longer sequences would normally be used. Top: initial graphing of sequences onto the map. Bottom: compacted graph produced by merging nodes (adapted from Limasset 2016).</p>","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#rna-seq-data-quality-checks","title":"RNA-seq Data Quality Checks <p> After the data is mapped, we have to perform quality checks using tools like FASTQC. The purpose of quality control checks of raw reads is to detect PCR bias, contamination, sequencing errors, and other artifacts. These quality checks look for GC content, adapters, number of reads/fragments (k-mers), and duplicate reads. Further, read quality drops towards the 3\u2019 end and can affect transcript mapping. After you find the low quality data, you can remove them using Trimmomatic <p> Below are the things I don't really understand, and needs to pay a lot some attention to. <p> The percentage of mapped reads (to a reference genome or transcriptome) is also an indicator of sequencing accuracy. A high percentage of mapped reads is expected when a well-annotated genome is available. Conversely, a low percentage can indicate RNA contamination from rRNA or non-coding RNAs. Software packages like NOISeq (Tarazona 2015) or EDASeq (Risso 2011) can be used for such analyses. <p> The GC content and clustering of mapped reads close to the 3\u2019 end of poly(A)-enriched samples are important indicators of PCR bias and overall RNA quality, respectively. Tools like Picard, RSeQC and Qualimap are useful in quality checks during mapping. Finally, statistical analysis of replicate experiments should indicate a Spearman R2\u2009value which is &gt;\u20090.9 (Mortazavi 2008). In cases where biological heterogeneity is expected, other forms of statistical analysis are recommended.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#specific-applications","title":"Specific Applications","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#differential-gene-expression-analysis","title":"Differential Gene Expression Analysis <p> One of the most common uses of RNA-seq is to determine how gene expression changes in response to disease pathologies, therapeutic intervention, or other stimuli. Differential gene expression (DGE) analysis compares different experimental samples and uses toolkits to evaluate if the observed difference between normalized read counts of a gene is statistically significant (D\u00fcndar 2015). DGE is performed following the initial alignment, quantitation and normalization steps, and has two main goals:  <ol> <li>Assessing the magnitude of the difference. <li>Assessing the significance of the difference.   <p> Popular tools in this space are edgeR (Robinson 2010), DESeq2 (Anders and Huber, 2010; Love 2014), and limma-voom (Ritchie 2015).","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#small-rnas","title":"Small RNAs <p> Small RNAs are a class of non-coding regulatory RNAs that are characterized by lengths shorter than 200 nucleotides. This class includes miRNAs, short-interfering RNAs (siRNAs), and Piwi-interacting RNAs (piRNAs), amongst others. The sequencing strategy for these RNAs are different because most are between 18 and 30 nucleotides. In a standard small RNA-seq experiment, all reads are aligned to a reference genome using tools like Bowtie2 (Langmead 2012), STAR (Dobin 2013), or Burrows-Wheeler Aligner (Li 2009), or aligners like PatMaN (Pr\u00fcfer 2008) and MicroRazerS (Emde 2010). Contamination from degraded mRNA can skew read data, so it is critical to check for reads that map to high-abundance housekeeping genes.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#alternative-splicing","title":"Alternative Splicing <p> Differential splicing of mRNA leads to different protein products from a single gene. Many diseases, including cancer have been linked to splicing misregulation, which is why RNA-seq is routinely used to study this phenomena. Alternate splicing is difficult to study using standard short-read RNA-seq; however numerous algorithms are available. The two DGE methods used to analyze alternate splicing are isoform-based (cuffdiff2 and DiffSplice) or count-based, which includes exon-based (DEXSeq, edgeR, JunctionSeq and limma) and event-based (dSpliceType, MAJIQ, rMATS and SUPPA/SUPPA2). Isoform-based methods use sequencing reads to construct the full transcript and measure abundance prior to differential expression analysis (Trapnell 2013; Hu 2013). Count-based methods count different features to determine percentage spliced, exons, and junctions (Anders 2012; Robinson 2010; Hartley 2016; Ritchie 2015; Zhu 2015; Vaquero-Garcia 2016; Shen 2014; Alamancos 2015; Trincado 2018).","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#conclusions","title":"Conclusions <p>RNA-seq has revolutionized the transcriptomics field and new computational tools continue to help tackle the bottlenecks in data analysis and downstream modeling. Single-cell analysis and long-read RNA sequencing are two areas that are quickly evolving, with future developments expected to address limitations with low-abundance starting RNA and constructing long transcripts.","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#extra","title":"Extra","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#single-cell-rna-seq","title":"Single-Cell RNA-Seq <p> Single-cell RNA-seq (scRNA-seq) is an emerging technology that reveals the unique gene expression signature of individual cells, which is otherwise lost in bulk studies. These experiments are inherently different from bulk RNA-seq and employ unique workflows and analysis strategies. A common practice in scRNA-seq is the use of spike-in molecules, like the External RNA Control Consortium (ERCC), as an internal control. The number of molecules corresponding to the spike-in is then used to normalize RNA abundance across all single cells. Unique molecular identifiers (UMIs) may also be included to barcode the molecules of interest as a way to control for PCR bias. One of the main challenges with scRNA-seq continues to be the limits on sequencing depth. Some computational tools for scRNA-seq are single-cell normalization (Brennecke 2014), Monocle (Trapnell 2014), and scLVM (Buettner 2015).","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/RNA-seq/#a-workflow-map","title":"A Workflow Map","text":"","tags":["RNA-Seq"]},{"location":"Bioinformatics/RNA-seq/Tools/","title":"The Tools of RNA-seq","text":"<p>  In this Article, you can learn about the tools in RNA-Seq. The articles come from these websites: <p>  General (with huge thanks to Wen Yi): <ul> <li> https://github.com/Blairewen/Arabidopsis-Pollen Remember to star her repository too if you visit Wen Yi's repo. <p>  FASTQC <ul> <li> https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/"},{"location":"Bioinformatics/RNA-seq/Tools/#fastqc","title":"FastQC <p>  FastQC is for the quality control of the raw data from sequencing. It's best to check that the data are good before you do anything further. <p>  You can use the user interface friendly FastQC java swing application. But when you are processing multiple files, you can use the terminal command <code>fastqc</code> in such a way that you cna process multiple files at the same time. <pre><code> fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] [-c contaminant file] seqfile1 .. seqfileN\n</code></pre> <p> Remember to switch your shell to bash when you execute this command. I don't actually know the alternative command for zsh, but there must be some kind of command.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#multiqc","title":"MultiQC <p> However, sometimes we have a lot of test data, and we don't actually have the time to check the HTML output of the FastQC for each and every file. Thus, we can use MultiQC. <pre><code>multiqc /raw_data_dir\n</code></pre> <p> Will auto generate a 4 in 1 html report.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#trimmomatic","title":"Trimmomatic <p> Installing trimmomatic is a very tricky thing to do on a M1 chip mac. I followed this instruction to get it finally done. <p> http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#fastp","title":"fastp <p> Basically fastp is just a all in one quality check machine. It can perform quality check and trim the data at the same time. <pre><code>fastp -i Spm_R1.fastq.gz -I Spm_R2.fastq.gz -o Spm_R1.fastp.fastq.gz -O Spm_R2.fastp.fastq.gz -w 8 -q 20 \u2013u 20 -j Spm.fastp.json -h Spm.fastp.html\n</code></pre> <p> Here is the code for fastp. <ul> <li> -i, --in1 is the input file name of read1 <li> -I, --in2 is the input file name of read2 <li> -o, --out1 is the output file name of read1 <li> -O, --out2 is the output file name of read2  <p> There are some other commands regarding whether to discard one of the pair end read or not, which can bee found by typing <code>fastp -help</code>. <ul> <li> -w, --thread means the thread number, default thread # is 2 <li> -q, --qualified_quality_phred the quality phred value that a base is qualified. Default is 15, meaning that &gt;=Q15 is qualified. <li> -u, --unqualified_percent_limit how many percents of bases are allowed to be unqualified (0~100). Default 40 means 40%. <li> -g force polyG tail trimmingmby default trimming is automatically enabled for Illumina data.  <p> And their are the commands that controls the outputs. <ul> <li> -j, --json the json format report file name (string [=fastp.json]) <li> -h, --html the html format report file name (string [=fastp.html])   <p> To download files from the server, use the scp command which works like this: <p> <code>scp username@sth.sth.sth.sth:/file/path/on/server.html /Local/path/to/store/file</code> <p> Remember not to add any extra space between.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#hisat2","title":"HISAT2 <p> The HISAT2 official website can be found here. It is a fast and sensitive alignment program for mapping next-generation sequencing reads. <pre><code>hisat2 -p 8 -x tair10_index --summary-file Spm.summary --dta-cufflinks -1 Spm_R1.fastp.cutadapt.fastq.gz -2 Spm_R2.fastp.cutadapt.fastq.gz -S output.sam\n</code></pre> <p> The basic usage of HISAT2 is: <pre><code>hisat2 [options]* -x &lt;ht2-idx&gt; {-1 &lt;m1&gt; -2 &lt;m2&gt; | -U &lt;r&gt; | --sra-acc &lt;SRA accession number&gt;} [-S &lt;sam&gt;]\n\n  &lt;ht2-idx&gt;  Index filename prefix (minus trailing .X.ht2).\n  &lt;m1&gt;       Files with #1 mates, paired with files in &lt;m2&gt;.\n             Could be gzip'ed (extension: .gz) or bzip2'ed (extension: .bz2).\n  &lt;m2&gt;       Files with #2 mates, paired with files in &lt;m1&gt;.\n             Could be gzip'ed (extension: .gz) or bzip2'ed (extension: .bz2).\n  &lt;r&gt;        Files with unpaired reads.\n             Could be gzip'ed (extension: .gz) or bzip2'ed (extension: .bz2).\n  &lt;SRA accession number&gt;        Comma-separated list of SRA accession numbers, e.g. --sra-acc SRR353653,SRR353654.\n  &lt;sam&gt;      File for SAM output (default: stdout)\n\n  &lt;m1&gt;, &lt;m2&gt;, &lt;r&gt; can be comma-separated lists (no whitespace) and can be\n  specified many times.  E.g. '-U file1.fq,file2.fq -U file3.fq'.\n</code></pre> <p> The interesting commands for HISAT2 are the following: <ul> <li> -p, --threads (int) means the number of threads you launch. Default is 1. <li> --summary-file print the alignment summary to this file. <li> --dta-cufflinks reprots alignments tailored specifically for cufflinks.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#samtools","title":"samtools <p> Samtools is a tool to handle sam, bam and cram files. <pre><code>samtools view -ShuF 4 -q 30 -f 2 -@ 2 file.name.sam | samtools sort -@ 2 -o output/file.bam \n\nsamtools view [options] &lt;in.bam&gt;|&lt;in.sam&gt;|&lt;in.cram&gt; [region ...]\n</code></pre> <p> <code>samtools view</code>is for viewing the bam/sam/cram file in bam/sam/cram type. <ul> <li> -S Ignored (the input format is auto-detected). <li> -h,--with-header Include header in the SAM output. <li> -u,--uncompressed Uncompressed BAM output (and default to --bam). <li> -F FLAG Have none of the FLAGs. <li> -q int Have mapping quality &gt;= int. <li> -f FLAG Have all of the flags present. <li> -@ int The number of threads.  <li> -b output bam file  <p> <code>samtools sort</code> is sorting the data by your need. <p>- -u Set the compression level to 0 (uncompressed). <p> When you want to see your gene inside for insatance igv, you will also need to index your bam files.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#featurecounts","title":"featureCounts <p> FeatureCounts is a tool to quantify the counts on genes based on the bam file. A link to a desctiption of featureCounts is here. <pre><code>featureCounts [options] -a &lt;annotation_file&gt; -o &lt;output_file&gt; input_file1 [input_file2] ... \n</code></pre> <p> After using featureCounts, you can use your command line tools: <pre><code>cut -f1,7,...\n</code></pre> <p> To cut the columns you need.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#bedtools","title":"bedtools <pre><code>genomeCoverageBed -ibam Spm.sorted.bam -bg -split &gt; Spm.bdg\n</code></pre> <ul> <li> -ibam input bam files for coverage. Use <code>stdin</code> or <code>-</code> for a Unix pipe.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#cuffdiff","title":"cuffdiff <p>  Cuffdiff is a program included in cufflinks. You can use this program to find significant changes in transcript expression. Use <code>cuffdiff -h</code> to look for the manual.  <p> When cuffdiff give you all 0 counts, there might be something wierd with your sam file. The name of the chromosome might be named wrong. Instead of naming them 'chrN' they are just named with 'N'.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#at-last-deseq2","title":"At Last ... DEseq2 <p> I think DEseq2 might need a seperate article.","text":""},{"location":"Bioinformatics/RNA-seq/Tools/#others","title":"Others <p> To communicate with the server using <code>scp</code> command, see here for more info.","text":""},{"location":"Bioinformatics/Xenopus/October/","title":"October","text":""},{"location":"Bioinformatics/Xenopus/October/#motif-analysis","title":"Motif analysis <p> September 23rd, got my first ever project from Prof.Chen Wei. The first important step should be motif analysis. (my actual work-list is here) <p> To summarize, finding the linkage between two TF proteins which regulates gene expression is what we should do. By finding the linkage between the motifs of proteins in the promoter zone of the gene, we can hypothesis that some of the proteins have interactions with each other.","text":""},{"location":"Bioinformatics/Xenopus/October/#pipelines","title":"Pipelines","text":""},{"location":"Bioinformatics/Xenopus/October/#preparing-raw-materials","title":"Preparing raw materials <p> Time: October 2nd  Several raw materials are needed for this analysis. Including: -  The motif files of the TF proteins we are interested in. -  Classify the ATAC-seq peaks and filter the non-promoter ones. -  Getting the sequence for the filtered peaks. <p> The motif files of the TF proteins are fairly easy to obtain. Go to JASPR database and download the motifs you need. You can download multiple motifs in one text file by adding them to the cart. <p> Classifying the ATAC-seq files need some Linux skills (which sadly I don't have) and we also need Homer. First, we have to classify our own unique genome. Because we are using frogs, which are not very common, Homer requires us to build our own reference genome, which can be easily done following the guidelines here. This procedure requires the FASTA file for the genome and the gtf file for the genome annotation. <pre><code>loadGenome.pl -name XenTr10 -fasta Xentr10.repeatMasked.fasta -gtf Xentr10.0.gene.chr.gtf -org xenopus\n</code></pre> <p> After loading our own genome into Homer, we can classify the peaks we get from our normal ATAC-seq pipeline. <pre><code>annotatePeaks.pl st9-2_peaks.narrowPeak XenTr10 &gt; st9-2-annotated.txt\n</code></pre> <p></p> <p> Within the text file, there are peaks that are classified as intron, intergenic, promoter etc. We need to filter out the ones containing promoters. So this is where the powerful awk comes. <pre><code>awk '/promoter/ {print}'  st9-2-annotated.txt &gt; st9-2-promoter.txt\n</code></pre> <p> This simple command can filter out all the lines containing promoter into a new file. We also need to convert the new text file into bed format by cutting out some of the important lines (you can use awk for this as well). <pre><code>cut -f 2,3,4,16 XXX.txt &gt;XXX.bed\n</code></pre> <p> Thus we can get a bed format file that contains only the promoter peaks from the ATAC-seq peaks. <p> At last, we get our filtered peaks and map them back to the genome, thus obtaining their sequence. Using bedtools we can finish these steps very quickly.  <pre><code>bedtools getfasta -fi Xentr10.repeatMasked.fasta -bed xxx.bed -fo output.fa -name\n</code></pre>","text":""},{"location":"Bioinformatics/Xenopus/October/#finding-the-motifs","title":"Finding the motifs <p> After we got our wanted sequence of all the promoters of the ATAC-seq peaks, we would like to see where are the motifs of the two TF proteins located, if at all, in these promoter sequences. Do they really activate the gene expression? Or that they are not bound to these sites. We use fimo from meme to match the motifs with our sequence. <pre><code>fimo --o dir/fimo OTX1.meme st9-2-promoter-gene.fa\n</code></pre> <p> Thus you get all the matches of the motif and your peaks.","text":""},{"location":"Bioinformatics/Xenopus/October/#polishing-the-r-program","title":"Polishing the R program <p>  Time: October 3rd and 4th <p> After we find the motifs of E2F1 and OTX1 and their location in our genome, we can see their length and location. By finding correlation between their position and distance, we might discover patterns.","text":""},{"location":"Bioinformatics/Xenopus/October/#relationship-between-e2f1-and-otx1","title":"Relationship between E2F1 and OTX1 <p> E2F1 and OTX1 motif might exist in the same part of the chromosome (in the same peak), we would like to take these part out and find the relationship between the two motifs, whether one motif is usually in the upstream of the other, the general distance between the two motifs etc. I will see tomorrow if I can remember to upload the codes onto GitHub, but actually I should. <p> After fiddling with the parameters (mainly just changing the binSize variable in the function lapply), we found out that, out of 1518 co-occurrence of E2F1 and OTX1, 30 of them have very similar distance between them. Roughly 1000bp between the two motifs (E2F1 motif are to the upstream of OTX1). These motifs with strange distance between them are found on chormosome 3, just in front of a set of different genes involved in t-RNA formation. <p> These interesting little sets of motifs are later investigated by me. Because I was only using two stage-9 ATAC-seq data, I cannot be 100% sure that these motifs are only there because of pure chance or technical error during ATAC-seq. <p> After examining stage8 and stage7 ATAC-seq data, I found the same pattern in stage8, but not in stage7. Stage8 ATAC peaks still have overlaps with the motifs on chr3, but in stage7, only E2F1 motifs can be found in the peaks of chr3. This might suggest that the OTX1 protein have something to do with the activation of transcription, or that E2F1 have something to do with t-RNA. I just don't know yet and we might need to look further into this with more data. ChIP-Seq data shows that in stage9, E2F1 and OTX1 proteins really did bind to the chromatin, and a 1000bp apart motif pair can be found from the data, but I didn't have the ChIP-seq data, and I still need time to get access to QiMing, this might not be finished so soon.","text":""},{"location":"Bioinformatics/Xenopus/October/#technical-issue-found-with-promoter-definition","title":"Technical Issue Found with Promoter Definition <p> The nature of the 1000bp apart motif are identified by me after preparing for the PPT for the small talk next week. I'm both sad and happy about this. Sad because it is not something very beautiful, instead it was a glitch in our definition of the promoter. But I am also happy that I discovered this glitch early into this project, and understanding the nature of it will save us a lot of time in the future. <p></p> <p> While I was making the ppt, I discovered that, actually, the interesting 1000bp apart motifs in our ChIP-Seq data are actually the same one. They are read three times due to out definition of the promoter. Which is just taking the taking 2000bp upstream and downstream of the TSS of the gene. So when it comes to two genes whose TSS are close to each other, their promoters overlap and are counted repeatedly (in this case 3 times). Thus leading to multiple promoters containing the same set of motif, and multiple counts at a certain distance. <p> Futher discussion with Prof.Chen and Dr.Cui are needed, and it's scheduled next week. I think I will give myself a break from work, and maybe spend some time on biochemistry and DSAA.","text":""},{"location":"Biology/","title":"Biology!!!","text":"<p> My major is Bioinformatics. So most of my work, of course, is related to biology. I have an interesting story about choosing biology as my major. In the freshman year, I chose the course Introduction to Life Science at first. Since I'm not that interested in biology at that moment, I didn't choose the required course Principle of Biology. But in the first class, the professor told all of us, \"Don't expect to learn anything new in Introduction to Life Science!\". And I was like,\" Whaaat? Then what am I choosing this class for?\" So after the first class I changed to Principle of Biology and met three wonderful teachers Prof. Chen Wei, Prof. Xiao Bo, and Prof. Guo Hongwei. They ignited my passion towards biology, and I decided to major in biology. (And because I want to learn some math and computer science, I finally chose bioinformatics.) <p> Click on the files on the left side to learn more! </p>"},{"location":"Biology/Struct/coot_install/","title":"Installing Coot on Mac","text":"<p> There are two types of ways to install Coot on MacOS. One is to simply install the CCP4 package, which have coot bundled inside it. The other method is installing it through homebrew. I will start with the one I found the most useful."},{"location":"Biology/Struct/coot_install/#installing-through-ccp4-package","title":"Installing Through CCP4 package <p> The Collaborative Computational Project Number 4 was a very old project indeed. But it contains a lot of useful toos for macromolecule crystollography, including Coot. We just need to go to the website of CCP4 and click download. <p></p> <p> However, remember to pay attention to the ATTENTION part in front of the Download Now! You need to have XQuartz installed before everything can work.  <p> So if you can't get any of the CCP4 applications to work, don't worry and calm down, just install XQuartz and everything will be fine.","text":""},{"location":"Biology/Struct/coot_install/#installing-through-homebrew","title":"Installing Through Homebrew <p> If you are not feeling very comfortable and don't want to take the more easier path, you can also install it through Homebrew. Take a very good look at this github repo, and you will find that your path is very clear. <pre><code>wget https://raw.githubusercontent.com/YoshitakaMo/homebrew-bio/coot/Formula/coot.rb\nbrew install ./coot.rb --verbose --HEAD\n</code></pre> <p> These two commands are needed to install Coot. However, only these two commands are not enough. You need to ensure that you have the right edition of gtk+3 because Coot does not support the latter versions very well. Follow this issue and download an older version of gtk+3. But I need to warn you, although the new Coot looks cool, it doesn't work very well and have a lot of bugs.","text":""},{"location":"Biology/Struct/coot_install/#have-fun-with-coot","title":"Have Fun with Coot!","text":""},{"location":"CS/","title":"Computer Science","text":"<p> Another half for the name Bioinformatics is informatics. That means we have to use a lot of computing tools to analyze the data we got from our experiment. I am a rookie in the field of computer science, and have little coding experience before university. But after the Java class, I found that I'm rather interested in computer science, and are more than willing to learn more about it. <p> Click on the files on the left side to learn more!"},{"location":"CS/Learn%20CS/Discrete_review/","title":"Learning Discrete Mathematics","text":""},{"location":"CS/Learn%20CS/Discrete_review/#logic-and-mathematical-proofs","title":"Logic and Mathematical Proofs","text":"<p>Proposition: declarative sentence that is either true or false, but not both.</p> <p>Tautology: A compound proposition that is always true, regardless of the truth values of the variables involved.</p> <p>Contradiction: a compound proposition that is always false.</p> <p>Logical Equivalence: denoted by \\(p \\equiv q\\), if \\(p \\leftrightarrow q\\) is a tautology. \\(p\\) and \\(q\\) always have the same truth value. Logically equivalent propositions can be determined with truth tables or logical equivalences.</p> Equivalence Name \\(p \\land T \\equiv p\\) \\(\\\\\\) \\(p \\lor F \\equiv p\\) Identity Law \\(p \\lor T \\equiv T\\) \\(\\\\\\) \\(p \\land F \\equiv F\\) Domination Law \\(p \\lor p \\equiv p\\) \\(\\\\\\) \\(p \\land p \\equiv p\\) Idempotent Law \\(\\neg(\\neg p) \\equiv p\\) Double Negation Law \\(p \\lor q \\equiv q \\lor p\\) \\(\\\\\\) \\(p \\land q \\equiv q \\land p\\) Commutative Law \\((p \\lor q) \\lor r \\equiv p \\lor (q \\lor r)\\) \\(\\\\\\) \\((p \\land q) \\land r \\equiv p \\land (q \\land r)\\) Associative Law \\(p \\lor (q \\land r) \\equiv (p \\lor q) \\land (p \\lor r)\\) \\(\\\\\\) \\(p \\land (q \\lor r) \\equiv (p \\land q) \\lor (p \\land r)\\) Distributive Law \\(\\neg(p \\land q) \\equiv \\neg p \\lor \\neg q\\) \\(\\\\\\) \\(\\neg(p \\lor q) \\equiv \\neg p \\land \\neg q\\) De Morgan's Law \\(p \\lor (p \\land q) \\equiv p\\) \\(\\\\\\) \\(p \\land (p \\lor q) \\equiv p\\) Absorption Law \\(p \\lor \\neg p \\equiv T\\) \\(\\\\\\) \\(p \\land \\neg p \\equiv F\\) Negation Law \\(p \\rightarrow q \\equiv \\neg p \\lor q\\) Implication Law \\(p \\leftrightarrow q \\equiv (p \\rightarrow q) \\land (q \\rightarrow p)\\) Equivalence Law <p>Predicate Logic: make statements about variables that can be either true or false.</p> <p>Quantifiers: \\(\\forall\\) (for all) and \\(\\exists\\) (there exists). Quantifiers can exchange positions if they are of the same type and influencing the same domain.</p> <p>Validity: An argument form with premises \\(p_1, p_2, ..., p_n\\) and conclusion \\(c\\) is valid if and only if the compound proposition \\((p_1 \\land p_2 \\land ... \\land p_n) \\rightarrow c\\) is a tautology.</p> <p>Rules of Inference:</p> Rule Tautology Name \\(\\begin{array}{ll} &amp; p \\rightarrow q \\\\ &amp; p \\\\ \\hline \\therefore &amp; q \\\\ \\end{array}\\) \\((p \\land (p \\rightarrow q)) \\rightarrow q\\) Modus Ponens \\(\\begin{array}{ll} &amp; p \\rightarrow  q \\\\ &amp; \\neg q \\\\ \\hline \\therefore &amp; \\neg p \\\\ \\end{array}\\) \\((\\neg q \\land (p \\rightarrow q)) \\rightarrow \\neg p\\) Modus Tollens \\(\\begin{array}{ll} &amp; p \\rightarrow q \\\\ &amp; q \\rightarrow r \\\\ \\hline \\therefore &amp; p \\rightarrow r \\\\ \\end{array}\\) \\(((p \\rightarrow q) \\land (q \\rightarrow r)) \\rightarrow (p \\rightarrow r)\\) Hypothetical Syllogism \\(\\begin{array}{ll} &amp; p \\lor q \\\\ &amp; \\neg p \\\\ \\hline \\therefore &amp; q \\\\ \\end{array}\\) \\(((p \\lor q) \\land \\neg p) \\rightarrow q\\) Disjunctive Syllogism \\(\\begin{array}{ll} &amp; p \\\\ \\hline \\therefore &amp; p \\lor q \\\\ \\end{array}\\) \\(p \\rightarrow (p \\lor q)\\) Addition \\(\\begin{array}{ll} &amp; p \\land q \\\\ \\hline \\therefore &amp; p \\\\ \\end{array}\\) \\((p \\land q) \\rightarrow p\\) Simplification \\(\\begin{array}{ll} &amp; p \\\\ &amp; q \\\\ \\hline \\therefore &amp; p \\land q \\\\ \\end{array}\\) \\((p \\land q) \\rightarrow (p \\land q)\\) Conjunction <p>Methods of Proving Theorems:</p> <ol> <li> <p>Direct proof: Prove \\(p \\rightarrow q\\) directly.</p> </li> <li> <p>Proof by contrapositive: Prove \\(\\neg q \\rightarrow \\neg p\\).</p> </li> <li> <p>Proof by contradiction: Assume \\(\\neg q \\land p\\) are true, and show that this leads to a contradiction.</p> </li> <li> <p>Proof by cases: Prove \\(p \\rightarrow q\\) by dividing \\(p\\) into cases, show it's true for all possible cases.</p> </li> <li> <p>Proof of equivalence: Prove \\(p \\leftrightarrow q\\) by proving \\(p \\rightarrow q\\) and \\(q \\rightarrow p\\).</p> </li> </ol> <p>Examples:</p> <p>Prove that \\(\\sqrt{2}\\) is irrational.</p> <p>Hint: proof by contradiction, setting \\(\\sqrt{2} = \\frac{a}{b}\\), where \\(a\\) and \\(b\\) are coprime integers.</p> <p>Prove that there are infinitely many prime numbers.</p> <p>Hint: proof by contradiction. Set \\(p_n\\) as largest prime number, and consider \\(\\Pi_{i=1}^n p_i + 1\\).</p> <p>Show that there exist irrational numbers \\(x\\) and \\(y\\)such that \\(x^y\\) is rational.</p> <p>Hint: consider \\(\\sqrt{2}^{\\sqrt{2}}\\). Proof by cases.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#set-and-functions","title":"Set and Functions","text":"<p>A set is an unordered collection of objects. </p> <p>Proof of subset: Show \\(A \\subseteq B\\) by showing \\(x \\in A \\rightarrow x \\in B\\).</p> <p>Cardinality: If there are exactly \\(n\\) distinct elements in \\(S\\), where \\(n\\) is a non-negative integer, then \\(S\\) is a finite set and \\(n\\) is the cardinality of \\(S\\), denoted by \\(|S| = n\\).</p> <p>Power Set: The power set of a set \\(S\\) is the set of all subsets of \\(S\\), denoted by \\(\\mathcal{P}(S)\\).</p> <p>Tuples: The ordered n-tuple \\((a_1, a_2, ..., a_n)\\) is the ordered collection.  Different from sets, the order of elements in a tuple matters.</p> <p>Cartesian Product: The Cartesian product of sets \\(A\\) and \\(B\\), denoted by \\(A \\times B\\), is the set of all ordered pairs \\((a, b)\\) where \\(a \\in A\\) and \\(b \\in B\\).</p> \\[ A \\times B = \\{(a,b) | a \\in A \\land b \\in B \\} \\] <p>Union:  The union of sets \\(A\\) and \\(B\\), denoted by \\(A \\cup B\\), is the set of all elements that are in \\(A\\) or in \\(B\\).</p> \\[ A \\cup B = \\{x | x \\in A \\lor x \\in B\\} \\] <p>Intersection: The intersection of sets \\(A\\) and \\(B\\), denoted by \\(A \\cap B\\), is the set of all elements that are in both \\(A\\) and \\(B\\).</p> \\[ A \\cap B = \\{x | x \\in A \\land x \\in B\\} \\] <p>Difference: The difference of sets \\(A\\) and \\(B\\), denoted by \\(A - B\\), is the set of all elements that are in \\(A\\) but not in \\(B\\).</p> \\[ A - B = \\{x | x \\in A \\land x \\notin B\\} \\] <p>Complement: The complement of set \\(A\\) with respect to the universal set \\(U\\), denoted by \\(\\bar A\\), is the set of all elements in \\(U\\) that are not in \\(A\\).</p> \\[ \\bar A = \\{x | x \\in U \\land x \\notin A\\} \\] <p>Principle of Inclusion-Exclusion:</p> \\[ |A \\cup B| = |A| + |B| - |A \\cap B| \\] <p>Set Identity Laws:</p> Law Name \\(A \\cup \\emptyset = A\\) \\(\\\\\\) \\(A \\cap U = A\\) Identity Law \\(A \\cup U = U\\) \\(\\\\\\) \\(A \\cap \\emptyset = \\emptyset\\) Domination Law \\(A \\cup A = A\\) \\(\\\\\\) \\(A \\cap A = A\\) Idempotent Law \\(\\bar{\\bar A} = A\\) Double Complement Law \\(A \\cup B = B \\cup A\\) \\(\\\\\\) \\(A \\cap B = B \\cap A\\) Commutative Law \\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\) \\(\\\\\\) \\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\) Associative Law \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) \\(\\\\\\) \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) Distributive Law \\(A \\cup \\bar A = U\\) \\(\\\\\\) \\(A \\cap \\bar A = \\emptyset\\) Complement Law \\(A \\cup (A \\cap B) = A\\) \\(\\\\\\) \\(A \\cap (A \\cup B) = A\\) Absorption Law \\(A \\cup (B - A) = A \\cup B\\) \\(\\\\\\) \\(A \\cap (B - A) = \\emptyset\\) Difference Law \\(\\bar{A \\cup B} = \\bar A \\cap \\bar B\\) \\(\\\\\\) \\(\\bar{A \\cap B} = \\bar A \\cup \\bar B\\) De Morgan's Law <p>Proof of Set Identities:</p> <ol> <li> <p>Using membership tables.</p> </li> <li> <p>(e.g. \\(A=B\\)) By showing \\(A \\subseteq B\\) and \\(B \\subseteq A\\).</p> </li> <li> <p>Use set builder and logical equivalences. </p> </li> </ol> <p>Example for 3: Prove that \\(\\overline{A \\cap B} = \\bar A \\cup \\bar B\\).</p> \\[ \\begin{align*}     \\overline{A \\cap B} &amp; = \\{x | x \\notin (A \\cap B)\\} \\\\     &amp; = \\{x | \\neg (x \\in A \\land x \\in B)\\} \\\\     &amp; = \\{x | \\neg x \\in A \\lor \\neg x \\in B\\} \\\\     &amp; = \\{x | x \\notin A \\lor x \\notin B\\} \\\\     &amp; = \\{x | x \\in \\bar A \\cup x \\in \\bar B\\} \\\\     &amp; = \\bar A \\cup \\bar B \\end{align*} \\] <p>Functions: A function \\(f\\) from set \\(A\\) to set \\(B\\) assigns to each element \\(a\\) in \\(A\\) exactly one element \\(b\\) in \\(B\\).</p> <p>Injective (One-to-One): A function \\(f\\) is injective if and only if for all \\(a_1, a_2 \\in A\\), \\(f(a_1) = f(a_2) \\rightarrow a_1 = a_2\\).</p> <p>Surjective (Onto): A function \\(f\\) is surjective if and only if for all \\(b \\in B\\), there exists an \\(a \\in A\\) such that \\(f(a) = b\\).</p> <p>Bijective (One-to-One Correspondence): A function \\(f\\) is bijective if and only if it is both injective and surjective.</p> <p>Inverse Function: If \\(f\\) is a bijective function from set \\(A\\) to set \\(B\\), then the inverse function of \\(f\\), denoted by \\(f^{-1}\\), is a function from \\(B\\) to \\(A\\) such that \\(f^{-1}(f(a)) = a\\) for all \\(a \\in A\\) and \\(f(f^{-1}(b)) = b\\) for all \\(b \\in B\\).</p> <p>Composition of Functions: The composition of functions \\(f: A \\rightarrow B\\) and \\(g: B \\rightarrow C\\) is the function \\(g \\circ f: A \\rightarrow C\\) defined by \\((g \\circ f)(a) = g(f(a))\\) for all \\(a \\in A\\).</p> <p>Sequences: A sequence is a function from a subset of the set of integers to a set \\(S\\).  Sequence can be defined recursively by providing one or more initial terms and a rule for determining subsequent terms from those that precede them.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#cardinality-of-sets","title":"Cardinality of Sets","text":"<p>Countable Sets: A set that is either finite or has the same cardinality as the set of positive integers is countable.</p> <p>If there is a one-to-one function from set \\(A\\) to set \\(B\\), then \\(|A| \\leq |B|\\).</p> <p>If there is a one-to-one correspondence between set \\(A\\) and set \\(B\\), then \\(|A| = |B|\\).</p> <p>If A and B are sets with \\(|A| \\leq |B|\\) and \\(|B| \\leq |A|\\), then \\(|A| = |B|\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#algorithm-complexity","title":"Algorithm Complexity","text":"<p>Big-O Notation: A function \\(f(n)\\) is \\(O(g(n))\\) if there exist constants \\(c\\) and \\(n_0\\) such that \\(|f(n)| \\leq c|g(n)|\\) for all \\(n \\geq n_0\\).</p> <p>Big-Omega Notation: A function \\(f(n)\\) is \\(\\Omega(g(n))\\) if there exist constants \\(c\\) and \\(n_0\\) such that \\(|f(n)| \\geq c|g(n)|\\) for all \\(n \\geq n_0\\).</p> <p>Big-Theta Notation: A function \\(f(n)\\) is \\(\\Theta(g(n))\\) if there exist constants \\(c_1\\), \\(c_2\\), and \\(n_0\\) such that \\(c_1|g(n)| \\leq |f(n)| \\leq c_2|g(n)|\\) for all \\(n \\geq n_0\\).  In this case \\(f(n)\\) is both \\(O(g(n))\\) and \\(\\Omega(g(n))\\), \\(f(n)\\) and \\(g(n)\\) are of the same order.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#number-theory","title":"Number Theory","text":"<p>Divisibility: An integer \\(a\\) is divisible by an integer \\(b\\) if there exists an integer \\(c\\) such that \\(a = b \\cdot c\\). If a, b, c are integers, where \\(a \\not = 0\\), such that \\(a | b\\) and \\(a | c\\), then \\(a | (mb + nc)\\) whenever \\(m, n\\) are integers.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#congruence-relations","title":"Congruence Relations","text":"<p>If \\(a, b\\) are integers and \\(m\\) is a positive integer, then \\(a\\) is congruent to \\(b\\) modulo \\(m\\) if \\(m | (a - b)\\), denoted by \\(a \\equiv b \\pmod{m}\\). \\(a\\) and \\(b\\) are congruent modulo \\(m\\) if and only if there exists an integer \\(k\\) such that \\(a = b + km\\).</p> <p>Theorem: If \\(a \\equiv b \\pmod{m}\\) and \\(c \\equiv d \\pmod{m}\\), then:</p> <ol> <li> <p>\\(a + c \\equiv b + d \\pmod{m}\\).</p> </li> <li> <p>\\(ac \\equiv bd \\pmod{m}\\).</p> </li> </ol> <p>Corollary: Let \\(m\\) be a positive integer and let \\(a\\) and \\(b\\) be integers. If \\(a \\equiv b \\pmod{m}\\), then </p> <ol> <li> <p>\\((a + b) \\pmod{m} = (a \\pmod{m} + b \\pmod{m}) \\pmod{m}\\).</p> </li> <li> <p>\\((a \\cdot b) \\pmod{m} = (a \\pmod{m} \\cdot b \\pmod{m}) \\pmod{m}\\).</p> </li> </ol> <p>Computing \\(b^n \\mod m\\):  1. Let \\(n = (a_{k-1} ... a_1 a_0)_2\\).</p> <ol> <li> <p>Then \\(b^n = b^{(a_{k-1} ... a_1 a_0)_2} = b^{2^{k-1}a_{k-1}} \\cdot ... \\cdot b^{2a_1} \\cdot b^{a_0}\\).</p> </li> <li> <p>Recall that \\(a \\cdot b \\pmod{m} = (a \\pmod{m} \\cdot b \\pmod{m}) \\pmod{m}\\).</p> </li> <li> <p>Successively find \\(b \\mod m\\), \\(b^2 \\mod m\\), \\(b^4 \\mod m\\), ... until \\(b^{2^{k-1}} \\mod m\\). Multiply the components of \\(b^{2^i}\\) when \\(a_i = 1\\).</p> </li> </ol> <p>Pseudo code for computing \\(b^n \\mod m\\):</p> <pre><code>x = 1\npower = b mod m\nfor i = 0 to k-1\n    if a_i = 1\n        x = (x * power) mod m\n    power = (power * power) mod m\nreturn x\n</code></pre> <p>If \\(ca \\equiv cb \\pmod{m}\\), then \\(a \\equiv b \\pmod{m}\\) only if \\(\\gcd(a,b) = 1\\). </p>"},{"location":"CS/Learn%20CS/Discrete_review/#primes","title":"Primes","text":"<p>Prime Numbers: An integer \\(p &gt; 1\\) is prime if its only positive divisors are 1 and \\(p\\).</p> <p>Greatest Common Divisors: The greatest common divisor of integers \\(a\\) and \\(b\\), denoted by \\(\\gcd(a,b)\\), is the largest integer that divides both \\(a\\) and \\(b\\). If \\(a = p_1 ^{a_1} \\cdot ... \\cdot p_k ^{a_k}\\) and \\(b = p_1 ^{b_1} \\cdot ... \\cdot p_k ^{b_k}\\), then \\(\\gcd(a,b) = p_1 ^{\\min(a_1, b_1)} \\cdot ... \\cdot p_k ^{\\min(a_k, b_k)}\\).</p> <p>Relatively Prime: Integers \\(a\\) and \\(b\\) are relatively prime if \\(\\gcd(a,b) = 1\\).</p> <p>Least Common Multiple: The least common multiple of integers \\(a\\) and \\(b\\), denoted by \\(\\text{lcm}(a,b)\\), is the smallest positive integer that is divisible by both \\(a\\) and \\(b\\). If \\(a = p_1 ^{a_1} \\cdot ... \\cdot p_k ^{a_k}\\) and \\(b = p_1 ^{b_1} \\cdot ... \\cdot p_k ^{b_k}\\), then \\(\\text{lcm}(a,b) = p_1 ^{\\max(a_1, b_1)} \\cdot ... \\cdot p_k ^{\\max(a_k, b_k)}\\).</p> <p>Euclidean Algorithm: The Euclidean algorithm is an efficient method for computing the greatest common divisor of two integers \\(a\\) and \\(b\\). 1. If \\(a = 0\\), then \\(\\gcd(a,b) = b\\).</p> <ol> <li> <p>If \\(b = 0\\), then \\(\\gcd(a,b) = a\\).</p> </li> <li> <p>Otherwise, apply the Euclidean algorithm to \\(b\\) and \\(a \\mod b\\).</p> </li> </ol> <p>For example \\(\\gcd(287, 91)\\):</p> \\[ \\begin{align*}     287 &amp; = 3 \\cdot 91 + 14 \\\\     91 &amp; = 6 \\cdot 14 + 7 \\\\     14 &amp; = 2 \\cdot 7 + 0 \\end{align*} \\] <p>Lemma: Let \\(a = bq + r\\). Then \\(\\gcd(a,b) = \\gcd(b,r)\\). Proof: Let \\(d = \\gcd(a,b)\\) and \\(d' = \\gcd(b,r)\\). Since \\(a = bq + r\\), \\(d | a\\) and \\(d | b\\). Since \\(r = a - bq\\), \\(d | r\\). Thus \\(d | b\\) and \\(d | r\\), so \\(d | d'\\). Similarly, \\(d' | b\\) and \\(d' | r\\), so \\(d' | a\\). Since \\(a = bq + r\\), \\(d' | a\\). Thus \\(d' | d\\), so \\(d = d'\\) Another proof is also possible by showing all the common divisors of \\(a\\) and \\(b\\) are also common divisors of \\(b\\) and \\(r\\).</p> <p>Bezout's Theorem: If \\(a\\) and \\(b\\) are positive integers, then there exist integers \\(x\\) and \\(y\\) such that: </p> \\[ \\gcd(a,b) = ax + by \\] <p>This is also called the Bezout's Identity.</p> <p>Can be found with the extended Euclidean algorithm.</p> <p>Lemma: If \\(a | bc\\) and \\(\\gcd(a,b) = 1\\), then \\(a | c\\).</p> <p>Hint: Use Bezout's Theorem to express \\(c\\) with \\(a\\) and \\(b\\).</p> <p>Lemma: If \\(p\\) is prime and \\(p | a_1 a_2 ... a_n\\), then \\(p | a_i\\) for some \\(i\\).</p> <p>Hint: Use mathematical induction on \\(n\\). Then prove by cases.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#linear-congruences","title":"Linear Congruences","text":"<p>A congruence of the form \\(ax \\equiv b \\pmod{m}\\), where \\(m\\) is a positive integer, \\(a\\) and \\(b\\) are integers, and \\(x\\) is a variable, is called a linear congruence.</p> <p>The solutions to a linear congruence \\(ax \\equiv b \\pmod{m}\\) are all integers \\(x\\) that satisfy the congruence. (More than 1 solution)</p> <p>Modular Inverse: An integer \\(a\\) has a modular inverse modulo \\(m\\) if there exists an integer \\(\\bar{a}\\) such that \\(\\bar{a}a \\equiv 1 \\pmod{m}\\).</p> <p>We can solve the linear congruence \\(ax \\equiv b \\pmod{m}\\) by finding the modular inverse of \\(a\\) modulo \\(m\\) and multiplying both sides by the modular inverse.</p> <p>When does the inverse exist? The modular inverse of \\(a\\) modulo \\(m\\) exists if and only if \\(a\\) and \\(m\\) are relatively prime. The inverse is unique modulo \\(m\\).</p> <p>How do we find the inverse? With the extended Euclidean algorithm.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#chinese-remainder-theorem","title":"Chinese Remainder Theorem","text":"<p>Let \\(m_1, m_2, ... m_n\\) be pairwise relative prime positive integerse greater than 1 and \\(a_1, a_2, ..., a_n\\) be arbitrary integers. Then the system:</p> \\[ \\begin{align*}     x &amp; \\equiv a_1 \\pmod{m_1} \\\\     x &amp; \\equiv a_2 \\pmod{m_2} \\\\     &amp; ... \\\\     x &amp; \\equiv a_n \\pmod{m_n} \\end{align*} \\] <p>has a unique solution modulo \\(m = \\prod_{i=1}^n m_i\\). The solution is given by:</p> \\[ x = \\sum_{i=1}^n a_i M_i \\bar{M_i} \\pmod{m} \\] <p>where \\(M_i = \\frac{m}{m_i}\\) and \\(\\bar{M_i}\\) is the modular inverse of \\(M_i\\) modulo \\(m_i\\).</p> <p>If \\(m_1, m_2, ... m_n\\) are not pairwise relatively prime, then the system may have no solution or multiple solutions. But we can try to solve by translating the system into a system with pairwise relatively prime moduli. For \\(x \\equiv a_k \\pmod{m_k}\\), suppose \\(m_k = p_1^{a_1} \\cdot ... \\cdot p_k^{a_k}\\), where \\(p_i\\) are all primes, then we can solve the system by solving \\(x \\equiv a_k \\pmod{p_i^{a_i}}\\) for all \\(i\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#rsa-cryptosystem","title":"RSA Cryptosystem","text":"<p>Fermat's Little Theorem: If \\(p\\) is a prime number and \\(a\\) is an integer not divisible by \\(p\\), then: </p> \\[ a^{p-1} \\equiv 1 \\pmod{p}\\] <p>RSA Cryptosystem:</p> <ol> <li> <p>Choose two distinct prime numbers \\(p\\) and \\(q\\).</p> </li> <li> <p>Compute \\(n = pq\\) and \\(\\phi(n) = (p-1)(q-1)\\).</p> </li> <li> <p>Choose an integer \\(e\\) such that \\(1 &lt; e &lt; \\phi(n)\\) and \\(\\gcd(e, \\phi(n)) = 1\\).</p> </li> <li> <p>Compute the unique integer \\(d\\) such that \\(1 \\leq d &lt; \\phi(n)\\) and \\(ed \\equiv 1 \\pmod{\\phi(n)}\\).</p> </li> <li> <p>The public key is \\((n,e)\\) and the private key is \\((n,d)\\).</p> </li> <li> <p>To encrypt a message \\(M\\), compute \\(C = M^e \\pmod{n}\\).</p> </li> <li> <p>To decrypt a ciphertext \\(C\\), compute \\(M = C^d \\pmod{n}\\).</p> </li> </ol> <p>Proof of RSA: (Very short ver.) 1. \\(C^d = M^{ed} = M^{k\\phi(n) + 1} = M \\cdot (M^{\\phi(n)})^k\\).</p> <ol> <li> <p>By Fermat's Little Theorem, \\(M^{\\phi(n)} \\equiv 1 \\pmod{n}\\).</p> </li> <li> <p>Thus \\(C^d \\equiv M \\pmod{n}\\).</p> </li> </ol>"},{"location":"CS/Learn%20CS/Discrete_review/#mathematical-induction","title":"Mathematical Induction","text":"<p>Well Ordering Principle: Every nonempty set of nonnegative integers has a least element.</p> <p>Weak Principle of Mathematical Induction:</p> <ol> <li> <p>Basic Step: Show that \\(P(0)\\) is true.</p> </li> <li> <p>Inductive Step: Show that for all \\(k \\geq 0\\), if \\(P(k)\\) is true, then \\(P(k+1)\\) is true.</p> </li> </ol> <p>Strong Principle of Mathematical Induction:</p> <ol> <li> <p>Basic Step: Show that \\(P(0)\\) is true.</p> </li> <li> <p>Inductive Step: Show that for all \\(k \\geq 0\\), if \\(P(0), P(1), ..., P(k)\\) are true, then \\(P(k+1)\\) is true.</p> </li> </ol>"},{"location":"CS/Learn%20CS/Discrete_review/#recursion","title":"Recursion","text":"<p>To specify a function on the basis of recurrence:</p> <ol> <li> <p>Basis step (initial condition): specify the value of the function at \\(n = 0\\) or other initial conditions.</p> </li> <li> <p>Recursive step: specify a rule of finding the value of the function from its values at smaller arguments.</p> </li> </ol> <p>Finding the closed form of a recurrence relation:</p> <ol> <li> <p>Guess the form of the solution. (with Top-down or bottom-up approach)</p> </li> <li> <p>Use mathematical induction to prove the correctness of the guess.</p> </li> </ol> <p>Solving Linear Homogeneous Recurrence Relations:</p> \\[ a_n = c_1 a_{n-1} + c_2 a_{n-2} + ... + c_k a_{n-k} \\] <p>The characteristic equation is: </p> \\[ x^k - c_1 x^{k-1} - c_2 x^{k-2} - ... - c_k = 0 \\] <p>Suppose these characteristic roots \\(\\lambda_1, \\lambda_2, ..., \\lambda_r\\) have multiplicities \\(m_1, m_2, ... m_r\\). Then the general solution is:</p> \\[ a_n = \\sum_{i=1}^r \\sum_{j=1}^{m_i} c_{ij} n^{j-1} \\lambda_i^n \\] <p>where \\(\\lambda_i\\) are the characteristic roots and \\(c_{ij}\\) are constants determined by the initial conditions.</p> <p>Find all the \\(c_{ij}\\) with the initial conditions.</p> <p>Example: \\(a_n = 4a_{n-1} - 4a_{n-2}\\) with \\(a_0 = 1\\) and \\(a_1 = 0\\). The characteristic equation is \\(x^2 - 4x + 4 = 0\\), which has a double root \\(x = 2\\). Thus the general solution is \\(a_n = (c_1 + c_2 \\cdot n )\\cdot 2^n\\). Using the initial conditions, we find \\(c_1 = 1\\) and \\(c_2 = -1\\). Thus the closed form is \\(a_n = 2^n - n \\cdot 2^n\\).</p> <p>Solving Linear Nonhomogeneous Recurrence Relations:</p> \\[ a_n = c_1 a_{n-1} + c_2 a_{n-2} + ... + c_k a_{n-k} + f(n) \\] <p>Theorem:  If \\(a_n^{(p)}\\) is a particular solution to the nonhomogeneous recurrence relation, and \\(a_n^{(h)}\\) is the general solution to the corresponding homogeneous recurrence relation, then the general solution to the nonhomogeneous recurrence relation is \\(a_n = a_n^{(p)} + a_n^{(h)}\\). When \\(f(n)\\) is a polynomial, try to find a particular solution of the form \\(a_n^{(p)} = q(n)\\), where \\(q(n)\\) is a polynomial with the same root of the same degree as \\(f(n)\\). If the root is a solution to the characteristic equation, multiply by \\(n^m\\) where \\(m\\) is the multiplicity of the root in the characteristic equation.</p> <p>Example: Find all solutions of the recurrence relation \\(a_n = 5a_{n-1} - 6a_{n-2} + 7^n\\). The characteristic equation is \\(x^2 - 5x + 6 = 0\\), which has roots \\(x = 2, 3\\). The general solution to the homogeneous part is \\(a_n^{(h)} = c_1 \\cdot 2^n + c_2 \\cdot 3^n\\). Try a particular solution of the form \\(a_n^{(p)} = q(n) = A \\cdot 7^n\\). Substitute into the recurrence relation to find \\(A = \\frac{49}{20}\\). Thus the general solution is \\(a_n = c_1 \\cdot 2^n + c_2 \\cdot 3^n + \\frac{49}{20} \\cdot 7^n\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#counting","title":"Counting","text":"<p>Pigeonhole Principle: If \\(k\\) objects are placed into \\(n\\) boxes, then there is at least one box containing at least \\(\\lceil \\frac{k}{n} \\rceil\\) objects.</p> <p>Example proofs: Show that for every integer \\(n\\), there is a multiple of n that has only 0s and 1s in its decimal expansion</p> <p>Hint: Consider the remainders of \\(1, 11, 111, ..., 111...1\\) when divided by \\(n\\).</p> <p>During a month with 30 days, a baseball team plays at least one game a day, but no more than 45 games. Show that there must be a period of some number of consecutive days during which the team must play exactly 14 games.</p> <p>Hint: Number of games played before some day must be the same with another day + 14.</p> <p>Every sequence of \\(n^2 + 1\\) distinct real numbers contains a subsequence of length \\(n + 1\\) that is either strictly increasing or strictly decreasing.</p> <p>Hint: Consider the longest increasing and decreasing subsequence starting at \\(a_k\\). If there is no subsequence of length \\(n+1\\), then the two subsequences must have the same length starting at two different \\(a\\). Show that this is impossible.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#combinatorial-proofs","title":"Combinatorial proofs","text":"<p>A combinatorial proof of an identity is: - a proof that uses counting arguments to prove that both sides of the identity count the same objects but in different ways. - or a proof that is based on showing that there is a bijection between the sets of objects counted by the two sides of the identity.</p> <p>Also called double counting proofs and bijective proofs (respectively).</p> <p>Binomial Theorem: For any positive integer \\(n\\) and any real numbers \\(a\\) and \\(b\\), </p> \\[(a + b)^n = \\sum_{k=0}^n \\binom{n}{k} a^{n-k} b^k\\] <p>Corollary: </p> \\[\\sum_{k=0}^n \\binom{n}{k} = 2^n\\] <p>Proved by simply replacing \\(a = b = 1\\) in the binomial theorem. Also can be proved by counting. Left side counts all subsets of a set with \\(n\\) elements, right side counts the same thing since the object can either be in or out of the subset.</p> <p>Pascal's Identity: For any positive integers \\(n\\) and \\(k\\) with \\(n \\geq k\\), </p> \\[\\binom{n}{k} = \\binom{n-1}{k-1} + \\binom{n-1}{k}\\] <p>Counting Proof:  Left side counts all \\(k\\)-element subsets of a set with \\(n\\) elements. Right side counts the same thing by considering whether the \\(n\\)-th element is in the subset or not. If it's in the subset, then the remaining \\(k-1\\) elements are chosen from the first \\(n-1\\) elements. If it's not in the subset, then the \\(k\\) elements are chosen from the first \\(n-1\\) elements.</p> <p>More Identities:</p> \\[ \\binom{n+1}{r + 1} = \\sum_{j = r}^{n} \\binom{j}{r} \\] <p>Direct proof: Can be proved using the Pascal's Identity. Counting proof: Last place to find a final wanted item in a sequence of \\(n+1\\) random items with \\(r + 1\\) wanted items.</p> \\[ \\sum_{k = 1}^n k \\binom{n}{k} = n \\cdot 2^{n-1} \\] <p>Counting proof: Left side counts the number of ways to choose a committee with a president from a group of \\(n\\) people.  Right side counts the same thing by first choosing the president and then choosing the rest of the committee.</p> <p>Vandermonde's Identity: For any nonnegative integers \\(m, n, r\\),</p> \\[\\binom{m+n}{r} = \\sum_{k=0}^r \\binom{m}{k} \\binom{n}{r-k}\\] <p>Combinations with Repetition: The number of ways to distribute \\(r\\) objects to a set of \\(n\\) objects with repetition allowed is \\(\\binom{n+r-1}{r}\\).</p> <p>Example: Number of ways to distribute 10 identical candies to 4 children. Think of the candies as stars and the children as bars.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#generating-functions","title":"Generating functions","text":"<p>The generating function for the sequence \\(a_0, a_1, a_2, ...\\) is the infinite series</p> \\[G(x) = a_0 + a_1 x + a_2 x^2 + ... + a_k x^k ... = \\sum_{k=0}^\\infty a_k x^k \\] <p>We can transfer the problem of a combination problem into a probelm of finding coefficient of \\(x^r\\) of a combination of generating function.</p> <p>Common summation formula for generating functions:</p> <ol> <li> <p>\\(\\frac{1 - x^{n+1}}{1 - x} = 1 + x + x^2 + ... + x^n= \\sum_{k=0}^n x^k\\)</p> </li> <li> <p>\\((1-x)^{-1} = 1 + x + x^2 + ... = \\sum_{k=0}^\\infty x^k\\)</p> </li> <li> <p>\\((1-ax)^{-1} = 1 + ax + a^2x^2 + ... = \\sum_{k=0}^\\infty a^k x^k\\)</p> </li> <li> <p>\\((1-x)^{-2} = 1 + 2x + 3x^2 + ... = \\sum_{k=0}^\\infty (k+1)x^k\\)</p> </li> </ol> <p>Can be used to solve linear recurrence relations.</p> <p>For example: Consider the sequence \\(\\{a_n\\}\\) that satisfies the recurrence relation </p> \\[ a_n = 8 a_{n-1} + 10^{n-1} \\] <p>and the initial condition \\(a_1 = 9\\).</p> <p>Let \\(G(x) = \\sum_{n = 0}^\\infty a_n x^n\\). \\(a_0 = 1\\) can be calculated with \\(a_1\\). Then the recurrence relation can be written as:</p> \\[  \\begin{align*}     G(x) - a(0) &amp; = \\sum_{n = 1}^\\infty a_n x^n = 8 \\sum_{n = 1}^\\infty a_{n-1} x^{n-1} + \\sum_{n = 1}^\\infty 10^{n-1} x^{n-1} \\\\     &amp; = 8x \\sum_{n = 0}^\\infty a_n x^n + \\sum_{n = 0}^\\infty 10^n x^n \\\\     &amp; = 8x G(x) + x /(1 - 10x) \\\\     G(x) &amp; = \\frac{1-9x}{(1 - 8x)(1 - 10x)} \\\\     &amp; = \\frac{1}{2}(\\frac{1}{1 - 8x} + \\frac{1}{1 - 10x}) \\\\     &amp; = \\frac{1}{2}(\\sum_{n = 0}^\\infty 8^n x^n + \\sum_{n = 0}^\\infty 10^n x^n) \\\\     &amp; = \\sum_{n = 0}^\\infty \\frac{8^n + 10^n}{2} x^n  \\end{align*} \\] <p>Therefore \\(a_n = \\frac{8^n + 10^n}{2}\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#relations","title":"Relations","text":"<p>Reflexive Relation: A relation \\(R\\) on a set \\(A\\) is reflexive if for all \\(a \\in A\\), \\((a,a) \\in R\\). Number of reflexive relations: \\(2^{n(n-1)}\\).</p> <p>Irreflexive Relation: A relation \\(R\\) on a set \\(A\\) is irreflexive if for all \\(a \\in A\\), \\((a,a) \\notin R\\). Number of irreflexive relations: \\(2^{n(n-1)}\\).</p> <p>Symmetric Relation: A relation \\(R\\) on a set \\(A\\) is symmetric if for all \\(a, b \\in A\\), \\((a,b) \\in R \\rightarrow (b,a) \\in R\\). Number of symmetric relations: \\(2^{n(n+1)/2}\\).</p> <p>Antisymmetric Relation: A relation \\(R\\) on a set \\(A\\) is antisymmetric if for all \\(a, b \\in A\\), \\((a,b) \\in R \\land (b,a) \\in R \\rightarrow a = b\\). Note that \\((a,b) = (b,a)\\) can happen in \\(R\\) if they are both zeros. Number of antisymmetric relations: \\(2^n \\cdot 3^{n(n-1)/2}\\).</p> <p>Transitive Relation: A relation \\(R\\) on a set \\(A\\) is transitive if for all \\(a, b, c \\in A\\), \\((a,b) \\in R \\land (b,c) \\in R \\rightarrow (a,c) \\in R\\).</p> <p>Composite of Relations: The composite of relations \\(R\\) and \\(S\\), denoted by \\(R \\circ S\\), is the relation that consists of all pairs \\((a,c)\\) such that there exists an element \\(b\\) in the domain of \\(S\\) such that \\((a,b) \\in S\\) and \\((b,c) \\in R\\).</p> <p>Power of Relation: The \\(n\\)-th power of a relation \\(R\\), denoted by \\(R^n\\), is the relation defined inductively by:</p> \\[ R^1 = R, R^{n+1} = R^n \\circ R \\] <p>Theorem: The relation \\(R\\) on a set \\(A\\) is transitive if and only if \\(R^n \\subseteq R\\).</p> <p>Hint: Just use the definitions. Prove only if part with mathematical induction.</p> <p>\\(R^n(i,j) = 1\\) implies there is a path of length \\(n\\) from \\(i\\) to \\(j\\) in the directed graph of \\(R\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#closure-of-relations","title":"Closure of Relations","text":"<p>Closure: The closure of a relation \\(R\\) on a set \\(A\\) is the smallest relation \\(R'\\) that contains \\(R\\) with a certain property.  By smallest, we mean that \\(R'\\) is subset of every relation \\(Q\\) that contains \\(R\\) with the same property.</p> <p>Connectivity Relation: The connectivity relation \\(R^*\\) on a set \\(A\\) is the relation that contains all pairs \\((a,b)\\) such that there is a path from \\(a\\) to \\(b\\) in the directed graph of \\(R\\).</p> \\[ R^* = \\bigcup_{n=1}^\\infty R^n \\] <p>Theorem: There is a path of length \\(n\\) from \\(a\\) to \\(b\\) if and only if \\((a,b) \\in R^n\\).</p> <p>Hint: Proved by induction.</p> <p>Theorem: The transitive closure of a relation \\(R\\) equals the connectivity relation \\(R^*\\).</p> <p>Hint: Proved by showing that \\(R^*\\) is transitive and contains \\(R\\). Also that \\(R^*\\) is the smallest transitive relation containing \\(R\\). Since for all transitive relations \\(Q\\), \\(Q^* \\subseteq Q\\) and \\(R^* \\subseteq Q^*\\).</p> <p>Finding the transitive closure of a relation:</p> \\[ R^* = R \\cup R^2 \\cup ... \\cup R^n \\] <p>Theorem: Let \\(M_R\\) be the zero-one matrix of the relation \\(R\\). Then the matrix of the transitive closure \\(R^*\\) is </p> \\[ M_{R^*} = M_R \\lor M_{R^2} \\lor ... \\lor M_{R^n}\\] <p>Roy-Warshall Algorithm:</p> <p>Consider a list of vertices \\(v_1, v_2, ... v_n\\). Define a zero-one matrix </p> \\[ W_k = [w_{ij}^{(k)}] \\] <p>where \\(w_{ij}^{(k)} = 1\\) if there is a path from \\(v_i\\) to \\(v_j\\) that only uses vertices \\(v_1, v_2, ... v_k\\).</p> <p>To obtain the matrix \\(W_k\\), we can use the formula:</p> \\[ w_{ij}^{(k)} = w_{ij}^{(k-1)} \\lor (w_{ik}^{(k-1)} \\land w_{kj}^{(k-1)}) \\] <pre><code>W = M_R\nfor k = 1 to n\n    for i = 1 to n\n        for j = 1 to n\n            W[i,j] = W[i,j] or (W[i,k] and W[k,j])\n</code></pre> <p>The final matrix \\(W\\) is the matrix of the transitive closure of \\(R\\), \\(M_{R^*}\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#equivalence-relations","title":"Equivalence Relations","text":"<p>Equivalence Relation: A relation \\(R\\) on a set \\(A\\) is an equivalence relation if it is reflexive, symmetric, and transitive.</p> <p>Equivalence Class: The equivalence class of an element \\(a\\) in a set \\(A\\) with respect to an equivalence relation \\(R\\) is the set of all elements in \\(A\\) that are related to \\(a\\) by \\(R\\).</p> \\[ [a]_R = \\{ x \\in A | (a,x) \\in R \\} \\] <p>Partition: A partition of a set \\(A\\) is a collection of nonempty subsets of \\(A\\), i.e. \\(A_1, A_2, ... A_k\\), such that:</p> <ol> <li> <p>\\(A_i \\cap A_j = \\emptyset\\) for all \\(i \\not = j\\).</p> </li> <li> <p>\\(\\bigcup_{i = 1}^k = A\\).</p> </li> </ol> <p>Theorem: The equivalence classes of an equivalence relation on a set \\(A\\) form a partition of \\(A\\).</p> <p>Theorem: Let \\(\\{A_1, A_2, ..., A_n, ...\\}\\) be a partition of a set \\(A\\). Then, there is an equivalence relation \\(R\\) on \\(A\\), that has the sets \\(A_i\\) as its equivalence classes.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#partial-ordering","title":"Partial Ordering","text":"<p>Partial Ordering: A relation \\(R\\) on a set \\(A\\) is a partial ordering if it is reflexive, antisymmetric, and transitive.</p> <p>A set \\(S\\) with a partial ordering \\(R\\) is called a partially ordered set or poset, denoted by \\((S,R)\\).</p> <p>Then notation \\(a \\preccurlyeq b\\) is used to denote that \\((a,b) \\in R\\) in a poset \\((S,R)\\).</p> <p>The notation \\(a \\prec b\\) denotes that \\(a \\preccurlyeq b\\) and \\(a \\not = b\\).</p> <p>Comparability:</p> <p>The elements \\(a\\) and \\(b\\) of a poset \\((S,R)\\) are comparable if either \\(a \\preccurlyeq b\\) or \\(b \\preccurlyeq a\\).</p> <p>Totally Ordered: A poset \\((S,R)\\) is totally ordered if for all \\(a, b \\in S\\), either \\(a \\preccurlyeq b\\) or \\(b \\preccurlyeq a\\). \\(\\preccurlyeq\\) is called a total order.</p> <p>Hasse Diagram: A Hasse diagram of a poset \\((S,R)\\) is a graph that represents the partial ordering \\(R\\). By removing the edges that can be inferred from the transitive property of the relation, and all the loops.</p> <p>Lattice: A lattice is a poset \\((S,R)\\) such that for all \\(a, b \\in S\\), the set \\(\\{a,b\\}\\) has both a least upper bound and a greatest lower bound.</p> <p>Topological Sorting: A topological sorting of a Hasse graph \\(G\\) is an ordering of the vertices of \\(G\\) such that for every set of vertices \\((u,v)\\), \\(u\\) comes before \\(v\\) in the ordering.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#graph","title":"Graph","text":""},{"location":"CS/Learn%20CS/Discrete_review/#undirected-graphs","title":"Undirected Graphs","text":"<p>Simple Graph: A graph in which each edge connects two different vertices and where no two edges connect the same pair of vertices.</p> <p>Neighborhood: The set of all neighbors of a vertex \\(v\\) in a graph \\(G\\) is denoted by \\(N(v)\\).</p> <p>Degree: The degree of a vertex \\(v\\) in a graph \\(G\\), denoted by \\(\\deg(v)\\), is the number of edges incident to \\(v\\).</p> <p>Handshaking Theorem: If \\(G = (V,E)\\) is an undirected graph with \\(m\\) edges, then: </p> \\[ \\sum_{v \\in V} \\deg(v) = 2m \\] <p>Connectivity: Two vertices \\(u\\) and \\(v\\) in a graph \\(G\\) are connected if there is a path from \\(u\\) to \\(v\\). The graph is connected if every pair of vertices is connected.</p> <p>Simple Path: A simple path in a graph \\(G\\) is a path that does not contain any repeated vertices.</p> <p>Lemma: If there is a path from \\(u\\) to \\(v\\) in a graph \\(G\\), then there is a simple path from \\(u\\) to \\(v\\) in \\(G\\).</p> <p>Cut vertices: A vertex \\(v\\) in a connected graph \\(G\\) is a cut vertex if the graph \\(G - v\\) is disconnected.</p> <p>Cut edge: An edge \\(e\\) in a connected graph \\(G\\) is a cut edge if the graph \\(G - e\\) is disconnected.</p> <p>Edge Connectivity: The edge connectivity of a graph \\(G\\), denoted by \\(\\lambda(G)\\), is the minimum number of edges that must be removed to disconnect \\(G\\).</p> <p>Euler Circuit: An Euler circuit in a graph \\(G\\) is a circuit that contains every edge of \\(G\\) exactly once.</p> <p>Euler Path: An Euler path in a graph \\(G\\) is a path that contains every edge of \\(G\\) exactly once.</p> <p>Theorem: A connected multigraph with at least two vertices has an Euler circuit if and only if every vertex has even degree.</p> <p>Theorem  A connected multigraph has an Euler path if and only if it has exactly two vertices of odd degree.</p> <p>Hamiltonian Circuit: A Hamiltonian circuit in a graph \\(G\\) is a circuit that contains every vertex of \\(G\\) exactly once.</p> <p>Hamiltonian Path: A Hamiltonian path in a graph \\(G\\) is a path that contains every vertex of \\(G\\) exactly once.</p> <p>Planar Graph: A graph is planar if it can be drawn in the plane without any edges crossing.</p> <p>Theorem (Euler's Formula): If \\(G\\) is a connected planar graph with \\(v\\) vertices, \\(e\\) edges, and \\(r\\) regions, then:</p> \\[ r = e - v + 2 \\] <p>Proved by inductive hypothesis. Two cases: adding a vertex with edges, connecting two existing vertices.</p> <p>Corollary:  If \\(G\\) is a connected planar graph with \\(v\\) vertices and \\(e\\) edges, where \\(v \\geq 3\\), then:</p> \\[ e \\leq 3v - 6 \\] <p>Hint: when \\(v \\geq 3\\), \\(\\deg(r) \\geq 3\\). \\(2e = \\sum_{r \\in R} \\deg(r) \\geq 3r\\).</p> <p>If \\(G\\) is a connected planar graph, then \\(G\\) has a vertex of degree not exceeding 5.</p> <p>Show case is true with 1 or 2 vertices. Use the previous corollary to prove contradiction if every vertex has degree 6.</p> <p>In a connected palnar simple graph with \\(v\\) vertices and \\(e\\) edges, where \\(v \\geq 3\\) and no circuits of length three, then:</p> \\[ e \\leq 2 v - 4 \\] <p>Similar to previous corollary, but with \\(\\deg(r) \\geq 4\\).</p> <p>Kuratowski's Theorem: A graph is planar if and only if it does not contain a subgraph that is a subdivision of \\(K_5\\) or \\(K_{3,3}\\).</p>"},{"location":"CS/Learn%20CS/Discrete_review/#directed-graphs","title":"Directed Graphs","text":"<p>The in-degree of a vertex \\(v\\) in a directed graph \\(G\\), denoted by \\(\\deg^-(v)\\), is the number of edges that are incident to \\(v\\). The out-degree of a vertex \\(v\\) in a directed graph \\(G\\), denoted by \\(\\deg^+(v)\\), is the number of edges that are incident from \\(v\\).</p> <p>Let \\(G = (V,E)\\) be a directed graph with \\(m\\) edges. Then:</p> \\[ \\sum_{v \\in V} \\deg^-(v) = \\sum_{v \\in V} \\deg^+(v) = m \\] <p>Strongly Connected: A directed graph \\(G\\) is strongly connected if for every pair of vertices \\(u\\) and \\(v\\), there is a path from \\(u\\) to \\(v\\) and a path from \\(v\\) to \\(u\\).</p> <p>Weakly Connected: A directed graph \\(G\\) is weakly connected if the underlying undirected graph is connected.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#special-graphs","title":"Special Graphs:","text":"<p>Complete Graph: A complete graph on \\(n\\) vertices, denoted by \\(K_n\\), is a simple graph that contains an edge between every pair of distinct vertices.</p> <p>Cycle: A cycle of length \\(n\\), denoted by \\(C_n\\), is a simple graph that contains \\(n\\) vertices and \\(n\\) edges that form a cycle.</p> <p>\\(n\\)-dimensional Hypercube: The \\(n\\)-dimensional hypercube, denoted by \\(Q_n\\), is a graph that has \\(2^n\\) vertices, each of which is labeled with an \\(n\\)-bit string, and an edge between two vertices if their labels differ in exactly one bit.</p>"},{"location":"CS/Learn%20CS/Discrete_review/#bipartite-graphs","title":"Bipartite Graphs","text":"<p>A graph \\(G = (V,E)\\) is bipartite if the vertex set \\(V\\) can be partitioned into two sets \\(V_1\\) and \\(V_2\\) such that every edge in \\(E\\) connects a vertex in \\(V_1\\) to a vertex in \\(V_2\\).</p> <p>Complete Bipartite Graph: A complete bipartite graph \\(K_{m,n}\\) is a bipartite graph that contains \\(m\\) vertices in \\(V_1\\) and \\(n\\) vertices in \\(V_2\\), and an edge between every pair of vertices in \\(V_1\\) and \\(V_2\\).</p> <p>Matching: A matching in a graph \\(G = (V,E)\\) is a set of edges \\(M \\subseteq E\\) such that no two edges in \\(M\\) share a vertex.</p> <p>Complete Matching: A complete matching in a graph \\(G\\) with bipartition \\((V_1, V_2)\\), if every vertex in \\(V_1\\) is incident to an edge in the matching, in this case \\(|M| = |V_1|\\). Matching is just a subset of all the edges.</p> <p>Hall's Marriage Theorem: Let \\(G = (V,E)\\) be a bipartite graph with bipartition \\((V_1, V_2)\\). Then \\(G\\) contains a complete matching from \\(V_1\\) to \\(V_2\\) if and only if for every subset \\(S \\subseteq V_1\\), \\(|N(S)| \\geq |S|\\).</p> <p>Proof of \"only if\" is easy, just consider the definition. Proof of \"if\" is quite hard, can be proved with strong induction with proof by cases. Suppose for \\(|V_1| = k\\), the theorem holds for all \\(|\\mathcal{P}(V_1)| &lt; k\\) such that \\(\\forall A \\in \\mathcal{P}(V_1), |N(A)| \\geq |A| \\to\\) Complete matching between \\(V_1\\) and \\(V_2\\). Then consider the induction case with \\(|V_1| = k + 1\\). Two cases could be discussed. One with all subsets having more neighbours, and one with some subsets having one-to-one matching.</p> <p>Isomorphic Graphs: Two graphs \\(G_1 = (V_1, E_1)\\) and \\(G_2 = (V_2, E_2)\\) are isomorphic if there exists a bijection \\(f: V_1 \\to V_2\\) such that \\((u,v) \\in E_1\\) if and only if \\((f(u), f(v)) \\in E_2\\). Such a function \\(f\\) is called an isomorphism. Can be checked with:</p> <ol> <li> <p>Number of vertices and edges.</p> </li> <li> <p>Degree of vertices.</p> </li> <li> <p>Existence of circuits and paths with certain length etc.</p> </li> </ol>"},{"location":"CS/Learn%20CS/Logic_review/","title":"Learning Mathematical Logic","text":""},{"location":"CS/Learn%20CS/Logic_review/#predicate-logic","title":"Predicate Logic","text":""},{"location":"CS/Learn%20CS/Logic_review/#proposition-and-connectives","title":"Proposition and Connectives","text":"<p>Proposition: A proposition is a declarative sentence that can be judged as either true or false.</p> <p>Atomic Proposition: A proposition that does not contain any smaller part that is still a proposition is called an atomic proposition.</p> <p>Compound Proposition: A proposition that involves the assembly of multiple propositions is called a compound proposition.</p>"},{"location":"CS/Learn%20CS/Logic_review/#formal-language","title":"Formal Language","text":"<p>Formal language for propositional logic \\(\\mathscr{L}^P\\) is has three types of symbols:</p> <ol> <li> <p>Atomic propositions: \\(p, q, r, \\ldots\\)</p> </li> <li> <p>Connectives: \\(\\neg, \\land, \\lor, \\rightarrow, \\leftrightarrow\\)</p> </li> <li> <p>Parentheses: \\((, )\\)</p> </li> </ol> <p>Atom\\((\\mathscr{L}^P)\\):  Set of expressions of \\(\\mathscr{L}^P\\) consisting of a proposition symbol only.</p> <p>Form\\((\\mathscr{L}^P)\\): An expression \\(A \\in \\text{Form}\\left(\\mathscr{L}^P\\right)\\) if and only if it satisfies the following conditions:</p> <ol> <li> <p>\\(\\text{Atom} (\\mathscr{L}^P) \\subseteq \\text{Form} (\\mathscr{L}^P)\\)</p> </li> <li> <p>If \\(A \\in \\text{Form} (\\mathscr{L}^P)\\), then \\(\\neg A \\in \\text{Form} (\\mathscr{L}^P)\\)</p> </li> <li> <p>If \\(A, B \\in \\text{Form} (\\mathscr{L}^P)\\), then \\(\\left(A \\land B\\right), \\left(A \\lor B\\right), \\left(A \\rightarrow B\\right), \\left(A \\leftrightarrow B\\right) \\in \\text{Form} (\\mathscr{L}^P)\\)</p> </li> </ol> <p>Sub formula: A formula \\(A\\) is a sub formula of a formula \\(B\\) if \\(A\\) is a part of \\(B\\). \\(A\\) is a proper sub formula of \\(B\\) if \\(A\\) is a sub formula of \\(B\\) and \\(A \\neq B\\).</p> <p>Lemma: Every well-formed formula of \\(\\mathscr{L}^P\\) has a unique parse tree.</p> <p>Lemma: Every well-formed formula of \\(\\mathscr{L}^P\\) has an equal number of left and right parentheses.</p> <p>Lemma: Every proper prefix of a well-formed formula of \\(\\mathscr{L}^P\\) has more left parentheses than right parentheses. Every proper suffix of a well-formed formula of \\(\\mathscr{L}^P\\) has more right parentheses than left parentheses.</p> <p>Precedence:</p> <ol> <li> <p>\\((, )\\) has the highest precedence.</p> </li> <li> <p>Precedence level: \\(\\neg, \\land, \\lor, \\rightarrow, \\leftrightarrow\\).</p> </li> <li> <p>Connectives are assumed to associate to the right. e.g. \\(A \\land B \\land C\\) is equivalent to \\(A \\land (B \\land C)\\).</p> </li> </ol>"},{"location":"CS/Learn%20CS/Logic_review/#semantics","title":"Semantics","text":"<p>A truth valuation is a function \\(v : \\text{Atom} (\\mathscr{L}^P) \\rightarrow \\{0,1\\}\\). For \\(p \\in \\text{Atom} (\\mathscr{L}^P)\\), \\(v(p)\\) or \\(p^v\\) is the truth value of \\(p\\) under valuation \\(v\\).</p> <p>Every form \\(A \\in \\text{Form} (\\mathscr{L}^P)\\) has a truth value under a valuation \\(v\\). </p> <p>Proved by induction on the structure of \\(A\\).</p> <p>If for every valuation \\(v\\), \\(A^v = 1\\), then \\(A\\) is said to be a tautology. If for every valuation \\(v\\), \\(A^v = 0\\), then \\(A\\) is said to be a contradiction. If for some valuation \\(v\\), \\(A^v = 1\\), then \\(A\\) is said to be satisfiable.</p> <p>Semantics can be proved by: 1. Truth tables 2. Inductive proof 3. Valuation tree</p> <p>Logical equivalence:  Two formulas \\(A\\) and \\(B\\) are said to be logically equivalent if for every valuation \\(v\\), \\(A^v = B^v\\). \\(A\\) and \\(B\\) have same truth values in a truth table. \\(A \\leftrightarrow B\\) is a tautology.</p>"},{"location":"CS/Learn%20CS/Logic_review/#semantic-entailment","title":"Semantic Entailment","text":"<p>Let \\(\\Sigma\\) by a set of formulas (\\(\\Sigma \\subseteq \\text{Form}(\\mathscr{L}^P)\\)) and \\(A\\) be a formula (\\(A \\in \\text{Form}(\\mathscr{L}^P)\\)). We say:</p> <ul> <li> <p>\\(A\\) is a logical consequence of \\(\\Sigma\\), or</p> </li> <li> <p>\\(\\Sigma\\) (semantically) entails \\(A\\), or</p> </li> <li> <p>\\(\\Sigma \\models A\\)</p> </li> </ul> <p>if and onlyl if for every valuation \\(v\\), if \\(\\Sigma^v = 1\\) implies \\(A^v = 1\\).</p> <p>If \\(\\Sigma \\not \\models A\\), then there exists a truth valuation \\(v\\) such that \\(\\Sigma^v = 1\\) and \\(A^v = 0\\).</p> <p>Proved using direct proofs or truth tables, or by contradiction.</p> <p>\\(A \\models B\\) if and only if \\(A \\to B\\) is a tautology. \\(A \\equiv B\\) if and only if \\(A \\models B\\) and \\(B \\models A\\). \\(\\varnothing \\models A\\)  if and only if \\(A\\) is a tautology.</p> <p>\\(A_1, A_2, \\ldots, A_n \\models B\\) if and only if \\(\\varnothing \\models (A_1 \\land A_2 \\land \\ldots \\land A_n) \\to B\\).</p> <p>For any \\(n \\geq 1\\), there are \\(2^{2^n}\\) distinct truth functions of \\(n\\) variables.</p> <p>\\(2^n\\) different truth values, output of each can be either 0 or 1.</p> <p>Adequate Set: A set of connectives is said to be adequate if every well-formed formula can be expressed using only those connectives.</p> <p>Each of the sets \\(\\{\\neg , \\land\\}, \\{\\neg, \\lor\\}, \\{\\neg, \\rightarrow\\}\\) is an adequate set of connectives.</p>"},{"location":"CS/Learn%20CS/Logic_review/#proof-systems","title":"Proof Systems","text":"<p>If there is a proof with premises \\(\\Sigma\\) and conclusion \\(A\\), then we say that \\(A\\) is a syntactic consequence of \\(\\Sigma\\). Denoted by: \\(\\Sigma \\vdash A\\).</p> <p>3 types of proof systems:</p> <ol> <li> <p>Natural deduction: Few axioms and many rules.</p> </li> <li> <p>Hilbert system: Many axioms and only one rule. </p> </li> <li> <p>Resolution: Used to prove contradictions.</p> </li> </ol>"},{"location":"CS/Learn%20CS/Logic_review/#natural-deduction","title":"Natural Deduction","text":"<p>Alphabet of ND:</p> \\[ \\Sigma = \\{(, ), \\neg, \\land, \\lor, \\to,\\leftrightarrow, p, q, r, \\dots\\}\\] <p>Formulas of ND: 1. Atomic formulas are formulas. 2. If \\(A\\), \\(B\\) are formulas, then \\((\\neg A)\\), \\((A \\land B)\\), \\((A \\lor B)\\), \\((A \\to B)\\), \\((A \\leftrightarrow B)\\) are formulas. 3. Only expressions of \\(\\Sigma\\) that can be derived from the above rules are formulas.</p> <p>Inference rules:</p> <p>Reflexivity (Premise): $ \\Sigma \\cup {\\alpha } \\vdash \\alpha$.</p> <p>A table of all inference rules:</p> Name \\(\\vdash\\) Notation Inference Notation \\(\\land\\) - Introduction if \\(\\Sigma \\vdash \\alpha\\) and \\(\\Sigma \\vdash \\beta\\), then \\(\\Sigma \\vdash (\\alpha \\land \\beta)\\). \\(\\begin{array}{c} \\alpha \\\\ \\beta \\\\ \\hline (\\alpha \\land \\beta) \\end{array}\\) \\(\\land\\) - Elimination if \\(\\Sigma \\vdash (\\alpha \\land \\beta)\\), then \\(\\Sigma \\vdash \\alpha\\) and \\(\\Sigma \\vdash \\beta\\). \\(\\begin{array}{c} (\\alpha \\land \\beta) \\\\ \\hline \\alpha \\end{array}\\) and \\(\\begin{array}{c} (\\alpha \\land \\beta) \\\\ \\hline \\beta \\end{array}\\) \\(\\to\\) - Elimination if \\(\\Sigma \\vdash \\alpha\\) and \\(\\Sigma \\vdash (\\alpha \\to \\beta)\\), then \\(\\Sigma \\vdash \\beta\\). \\(\\begin{array}{c} \\alpha \\\\ (\\alpha \\to \\beta) \\\\ \\hline \\beta \\end{array}\\) \\(\\to\\) - Introduction if \\(\\Sigma \\cup \\{\\alpha\\} \\vdash \\beta\\), then \\(\\Sigma \\vdash (\\alpha \\to \\beta)\\). \\(\\begin{array}{c} \\boxed{\\begin{array}{c} \\alpha \\\\ \\vdots \\\\ \\beta \\end{array}} \\\\  \\hline \\alpha \\to \\beta \\end{array}\\) \\(\\lor\\) - Introduction if \\(\\Sigma \\vdash \\alpha\\), then \\(\\Sigma \\vdash (\\alpha \\lor \\beta)\\) and \\(\\Sigma \\vdash (\\beta \\lor \\alpha)\\). \\(\\begin{array}{c} \\alpha \\\\ \\hline (\\alpha \\lor \\beta) \\end{array}\\) and \\(\\begin{array}{c} \\alpha \\\\ \\hline (\\beta \\lor \\alpha) \\end{array}\\) \\(\\lor\\) - Elimination if \\(\\Sigma \\vdash (\\alpha \\lor \\beta)\\) and \\(\\Sigma \\cup \\{\\alpha\\} \\vdash \\gamma\\) and \\(\\Sigma \\cup \\{\\beta\\} \\vdash \\gamma\\), then \\(\\Sigma \\vdash \\gamma\\). \\(\\begin{array}{c} (\\alpha \\lor \\beta) \\\\ \\boxed{\\begin{array}{c} \\alpha \\\\ \\vdots \\\\ \\gamma \\end{array}} \\\\ \\boxed{\\begin{array}{c} \\beta \\\\ \\vdots \\\\ \\gamma \\end{array}} \\\\ \\hline \\gamma \\end{array}\\) \\(\\neg\\) - Introduction if \\(\\Sigma \\cup \\{\\alpha\\} \\vdash \\perp\\), then \\(\\Sigma \\vdash \\neg \\alpha\\). \\(\\begin{array}{c} \\boxed{\\begin{array}{c} \\alpha \\\\ \\vdots \\\\ \\perp \\end{array}} \\\\ \\hline \\neg \\alpha \\end{array}\\) \\(\\perp\\) - Introduction if \\(\\Sigma \\vdash \\neg \\alpha\\) and \\(\\Sigma \\vdash \\alpha\\), then \\(\\Sigma \\vdash \\perp\\). \\(\\begin{array}{c} \\neg \\alpha \\\\ \\alpha \\\\ \\hline \\perp \\end{array}\\) \\(\\perp\\) - Elimination if \\(\\Sigma \\vdash \\perp\\), then \\(\\Sigma \\vdash \\alpha\\). \\(\\begin{array}{c} \\perp \\\\ \\hline \\alpha \\end{array}\\) \\(\\neg \\neg\\) - Elimination if \\(\\Sigma \\vdash \\neg \\neg \\alpha\\), then \\(\\Sigma \\vdash \\alpha\\). \\(\\begin{array}{c} \\neg \\neg \\alpha \\\\ \\hline \\alpha \\end{array}\\) <p>And the law of excluded middle: \\(\\vdash (p \\lor \\neg p)\\).</p>"},{"location":"CS/Learn%20CS/Logic_review/#soundness-and-completeness","title":"Soundness and Completeness","text":"<p>\\(\\Sigma \\vdash A\\) means that \\(A\\) is a logical consequence (in the deduction system) of \\(\\Sigma\\).</p> <p>\\(\\Sigma \\models A\\) if and only if for every valuation \\(v\\), if \\(\\Sigma^v = 1\\), then \\(A^v = 1\\).</p> <p>Soundness: If \\(\\Sigma \\vdash A\\), then \\(\\Sigma \\models A\\). The conclusion of a proof is always a logical consequence of the premises.</p> <p>Proved by induction on the length of the proof.</p> <p>Completeness: If \\(\\Sigma \\models A\\), then \\(\\Sigma \\vdash A\\). Every logical consequence can be proved in this proof system.</p> <p>Quite difficult to prove. We want to prove: If \\(\\Sigma \\models A\\) holds, then \\(\\Sigma \\vdash A\\) is valid. We need to use three lemmas: </p> <ol> <li> <p>Lemma 1: If \\(\\Sigma \\models A\\), then \\(\\varnothing \\models (\\alpha_0 \\to (\\alpha_1 \\to (\\dots \\to (\\alpha_n \\to A)\\dots )))\\).</p> <p>Proved by contradiction. Assuming \\(\\varnothing \\not \\models (\\alpha_0 \\to (\\alpha_1 \\to (\\dots \\to (\\alpha_n \\to A)\\dots )))\\) and showing that \\(\\Sigma \\not \\models A\\).</p> </li> <li> <p>Lemma 2: If \\(\\varnothing \\models A\\), then $ \\varnothing \\vdash A$.</p> <p>Proved by induction on the structure of \\(A\\). Introduction of a new symbol \\(\\hat p\\) which is \\(\\neg p\\) when \\(p^v = 0\\) and \\(p\\) when \\(p^v = 1\\).</p> </li> <li> <p>Lemma 3: If \\(\\varnothing \\vdash (\\alpha_0 \\to (\\alpha_1 \\to (\\dots \\to (\\alpha_n \\to A)\\dots )))\\), then \\(\\{\\alpha_0, \\alpha_1, \\dots, \\alpha_n\\} \\vdash A\\). Which is equivalent to \\(\\Sigma \\vdash A\\).</p> <p>Direct proof (like pealing onions).</p> </li> </ol>"},{"location":"CS/Learn%20CS/Logic_review/#first-order-logic","title":"First Order Logic","text":""},{"location":"CS/Learn%20CS/Logic_review/#syntax","title":"Syntax","text":"<p>Domain:  A non-empty set of objects.</p> <p>Constant symbols:  Constants are used to denote objects in the domain.</p> <p>Variables:  \"Place holders\" for concrete values.</p> <p>Predicate:  A predicate is a function that returns a truth value. Representing the property of an individual object in the domain, or the relationship between multiple objects.</p> <p>Quantifiers:</p> <ol> <li> <p>Universal quantifier: \\(\\forall x\\), statement is true for all \\(x\\) in the domain.</p> </li> <li> <p>Existential quantifier: \\(\\exists x\\), statement is true for at least one \\(x\\) in the domain.</p> </li> </ol> <p>Function symbols: Functions that take objects in the domain as input and return an object in the domain as output, denoted as \\(f^{(n)}(x)\\).</p> <p>Terms: Is defined inductively as:</p> <ol> <li> <p>Constant symbols and variables are terms.</p> </li> <li> <p>If \\(f^{(n)}\\) is a function symbol of arity \\(n\\), and \\(t_1, t_2, \\ldots, t_n\\) are terms, then \\(f^{(n)}(t_1, t_2, \\ldots, t_n)\\) is a term.</p> </li> <li> <p>Nothing else is a term.</p> </li> </ol> <p>Intuitive understanding: Terms are expressions that denote objects in the domain.</p> <p>Atomic formula: An expression \\(\\mathscr{L}\\) is an element of \\(\\text{Atom}(\\mathscr{L})\\) if and only if it has one of the following two forms:</p> <ol> <li> <p>\\(P(t_1, \\dots, t_n)\\), where \\(P\\) is an \\(n\\)-ary predicate symbol and \\(t_1, \\dots, t_n \\in \\text{Term}(\\mathscr{L})\\).</p> </li> <li> <p>\\(t_1 = t_2\\), where \\(t_1, t_2 \\in \\text{Term}(\\mathscr{L})\\).</p> </li> </ol> <p>Intuitive understanding: Atomic formulas are expressions that denote a truth value, indicating the properties or relations of objects.</p> <p>Formulas: \\(\\alpha \\in \\text{Form}(\\mathscr{L})\\) if and only if it satisfies the following conditions:</p> <ol> <li> <p>\\(\\text{Atom}(\\mathscr{L}) \\subseteq \\text{Form}(\\mathscr{L})\\).</p> </li> <li> <p>If \\(\\alpha \\in \\text{Form}(\\mathscr{L})\\), then \\(\\neg \\alpha \\in \\text{Form}(\\mathscr{L})\\).</p> </li> <li> <p>If \\(\\alpha, \\beta \\in \\text{Form}(\\mathscr{L})\\), then \\(\\left(\\alpha \\land \\beta\\right), \\left(\\alpha \\lor \\beta\\right), \\left(\\alpha \\rightarrow \\beta\\right), \\left(\\alpha \\leftrightarrow \\beta\\right) \\in \\text{Form}(\\mathscr{L})\\).</p> </li> <li> <p>If \\(\\alpha \\in \\text{Form}(\\mathscr{L})\\) and \\(x\\) is a variable, then \\(\\forall x \\alpha, \\exists x \\alpha \\in \\text{Form}(\\mathscr{L})\\).</p> </li> </ol>"},{"location":"CS/Learn%20CS/Logic_review/#semantics_1","title":"Semantics","text":"<p>Scope: The scope of a quantifier is the formula that follows it. e.g. In \\(\\forall x P(x) \\land Q(x)\\), the scope of \\(\\forall x\\) is \\(P(x) \\land Q(x)\\).</p> <p>Free and bound variables: A variable \\(x\\) is free in a formula \\(\\alpha\\) if it is not in the scope of any quantifier for \\(x\\). Otherwise, it is bound.</p> <p>Sentence: A formula is a sentence if all its variables are bound.</p> <p>Closure: The closure of a formula \\(\\alpha\\) is the set of all sentences that can be formed by replacing the free variables in \\(\\alpha\\) with constants.</p> <p>Universal closure of \\(\\alpha\\) is \\(\\forall x_1 \\forall x_2 \\ldots \\forall x_n \\alpha\\).</p> <p>Existential closure of \\(\\alpha\\) is \\(\\exists x_1 \\exists x_2 \\ldots \\exists x_n \\alpha\\).</p>"},{"location":"CS/Learn%20CS/Logic_review/#meanings","title":"Meanings","text":"<p>To assign meanings to formulas of FOL, we need:</p> <ul> <li> <p>A domain \\(D\\).</p> </li> <li> <p>An interpretation \\(I\\) of non-logical symbols that assigns:</p> <ul> <li> <p>To each constant symbol \\(c\\), an object \\(c^I \\in D\\).</p> </li> <li> <p>To each function symbol \\(f^{(n)}\\), a function \\(f^I : D^n \\to D\\).</p> </li> <li> <p>To each predicate symbol \\(P^{(n)}\\), a relation \\(P^I \\subseteq D^n\\).</p> </li> </ul> </li> <li> <p>An interpretation of logical symbols:</p> <ul> <li> <p>Logical connectives, punctuations</p> </li> <li> <p>Quantifiers, variable symbols...</p> </li> </ul> </li> </ul> <p>After interpretation, terms in FOL represent individuals in the domain, while formulas represent propositions with fixed truth values.</p> <p>Interpretation: An interpretation \\(I\\) consists of:</p> <ul> <li> <p>A non-empty domain \\(D\\).</p> </li> <li> <p>For each constant symbol \\(c\\), an object \\(c^I \\in D\\).</p> </li> <li> <p>For each function symbol \\(f^{(n)}\\), a function \\(f^I : D^n \\to D\\).</p> </li> <li> <p>For each predicate symbol \\(P^{(n)}\\), a relation \\(P^I \\subseteq D^n\\).</p> </li> </ul> <p>Environment: An environment \\(E\\) is a function that assigns a value in the domain to every variable symbol in the language.</p> <p>Value of terms: With a fix interpretation \\(I\\) and environment \\(E\\), the value of a term \\(t\\) is denoted as \\(t^{(I,E)}\\), and is defined as:</p> <ul> <li> <p>If \\(t\\) is a constant symbol \\(c\\), then \\(t^{(I,E)} = c^I\\).</p> </li> <li> <p>If \\(t\\) is a variable symbol \\(x\\), then \\(t^{(I,E)} = E(x)\\).</p> </li> <li> <p>If \\(t = f(t_1, t_2, \\ldots, t_n)\\), then \\(t^{(I,E)} = f^I(t_1^{(I,E)}, t_2^{(I,E)}, \\ldots, t_n^{(I,E)})\\).</p> </li> </ul> <p>Value of atomic formulas: With a fix interpretation \\(I\\) and environment \\(E\\), the value of an atomic formula \\(P(t_1, t_2, \\ldots, t_n)\\) is denoted as \\(P(t_1, t_2, \\ldots, t_n)^{(I,E)}\\), and has the truth value of \\(P^I(t_1^{(I,E)}, t_2^{(I,E)}, \\ldots, t_n^{(I,E)})\\).</p> <p>Value of Well-Formed Formulas: With a fix interpretation \\(I\\) and environment \\(E\\), the value of a well-formed formula \\(\\alpha\\) is denoted as \\(\\alpha^{(I,E)}\\), and is defined as:</p> <ul> <li> <p>If \\(\\alpha\\) is an atomic formula, then \\(\\alpha^{(I,E)} = P(t_1, t_2, \\ldots, t_n)^{(I,E)}\\).</p> </li> <li> <p>If \\(\\alpha = \\neg \\beta\\), then \\(\\alpha^{(I,E)} = 1 - \\beta^{(I,E)}\\).</p> </li> <li> <p>If \\(\\alpha = \\beta \\land \\gamma\\), then \\(\\alpha^{(I,E)} = \\beta^{(I,E)} \\land \\gamma^{(I,E)}\\).</p> </li> <li> <p>If \\(\\alpha = \\beta \\lor \\gamma\\), then \\(\\alpha^{(I,E)} = \\beta^{(I,E)} \\lor \\gamma^{(I,E)}\\).</p> </li> <li> <p>If \\(\\alpha = \\beta \\to \\gamma\\), then \\(\\alpha^{(I,E)} = 1 - \\beta^{(I,E)} \\lor \\gamma^{(I,E)}\\).</p> </li> <li> <p>If \\(\\alpha = \\beta \\leftrightarrow \\gamma\\), then \\(\\alpha^{(I,E)} = \\beta^{(I,E)} \\leftrightarrow \\gamma^{(I,E)}\\).</p> </li> <li> <p>If \\(\\alpha = \\forall x \\beta\\), then \\(\\alpha^{(I,E)} = 1\\) if for all \\(d \\in D\\), \\(\\beta^{(I, E[x \\mapsto d])} = 1\\).</p> </li> <li> <p>If \\(\\alpha = \\exists x \\beta\\), then \\(\\alpha^{(I,E)} = 1\\) if there exists \\(d \\in D\\) such that \\(\\beta^{(I, E[x \\mapsto d])} = 1\\).</p> </li> </ul> <p>Assignment: For any environment \\(E\\) and domain element \\(d\\), the new environment \"\\(E\\) with \\(x\\) re-assigned to \\(d\\)\" is denoted as \\(E[x \\mapsto d]\\)., is given by:</p> \\[E[x \\mapsto d](y) = \\begin{cases} d &amp; \\text{if } y = x \\\\ E(y) &amp; \\text{otherwise} \\end{cases}\\]"},{"location":"CS/Learn%20CS/Logic_review/#entailment","title":"Entailment","text":"<p>An interpretation \\(I\\) and environment \\(E\\) satisfies a formula \\(\\alpha\\) if and only if \\(\\alpha^{(I,E)} = 1\\), denoted as \\(I \\models_E \\alpha\\). If they do not satisfy, then \\(I \\not \\models_E \\alpha\\), if \\(\\alpha^{(I,E)} = 0\\). If \\(I \\models_E \\alpha\\) for all environments \\(E\\), then \\(I \\models \\alpha\\).</p> <p>A formula \\(\\alpha\\) is:</p> <ul> <li> <p>valid if \\(I \\models \\alpha\\) for all interpretations \\(I\\) and \\(E\\).</p> </li> <li> <p>satisfiable if \\(I \\models \\alpha\\) for some interpretation \\(I\\) and \\(E\\).</p> </li> <li> <p>unsatisfiable if \\(I \\not \\models \\alpha\\) for all interpretations \\(I\\) and \\(E\\).</p> </li> </ul>"},{"location":"CS/Learn%20CS/Logic_review/#natural-deduction-fo-first-order-logic","title":"Natural Deduction fo First Order Logic","text":"<p>Substitutions: For a variable \\(x\\), a term \\(t\\), and a formula \\(\\alpha\\), the substitution of \\(t\\) for \\(x\\) in \\(\\alpha\\) is denoted as \\(\\alpha[t/x]\\) which denotes the resulting formula by replacing each free occurrence of \\(x\\) in \\(\\alpha\\) with \\(t\\).</p> <p>Natural deduction rules for FOL:</p> Name \\(\\vdash\\) Notation Inference Notation \\(\\forall\\) - Elimination if \\(\\Sigma \\vdash \\forall x \\alpha\\), then \\(\\Sigma \\vdash \\alpha[t/x]\\) for any term \\(t\\). \\(\\begin{array}{c} \\forall x \\alpha \\\\ \\hline \\alpha[t/x] \\end{array}\\) \\(\\forall\\) - Introduction if \\(\\Sigma \\vdash \\alpha[t/x]\\) with \\(t\\) not free in \\(\\Sigma\\) or \\(\\alpha\\), then \\(\\Sigma \\vdash \\forall x \\alpha\\). \\(\\begin{array}{c} \\boxed{\\begin{array}{c} t \\text{ fresh}\\  \\\\ \\vdots \\\\ \\alpha[t/x] \\end{array}} \\\\ \\hline \\forall x \\alpha \\end{array}\\) \\(\\exists\\) - Introduction if \\(\\Sigma \\vdash \\alpha[t/x]\\), then \\(\\Sigma \\vdash \\exists x \\alpha\\). \\(\\begin{array}{c} \\alpha[t/x] \\\\ \\hline \\exists x \\alpha \\end{array}\\) \\(\\exists\\) - Elimination if \\(\\Sigma \\cup \\{\\alpha[t/x]\\} \\vdash \\beta\\) with \\(t\\) fresh, then \\(\\Sigma \\cup (\\exists x \\alpha) \\vdash \\beta\\). \\(\\begin{array}{c} \\exists x \\alpha \\\\ \\boxed{\\begin{array}{c} \\alpha[t/x], t \\text{ fresh} \\\\ \\vdots \\\\ \\beta \\end{array}} \\\\ \\hline \\beta \\end{array}\\)"},{"location":"CS/Learn%20CS/Markdown/","title":"Learning Markdown","text":"<p>  Markdown is a kind of text file which can be converted to HTML with Markdown applications and Markdown. I find it very interesting and kinda cool to write things in this way."},{"location":"CS/Learn%20CS/Markdown/#basic-syntax","title":"Basic Syntax","text":""},{"location":"CS/Learn%20CS/Markdown/#headings","title":"Headings <pre><code>Markdown                    HTML\n# Heading level 1           &lt;h1&gt; Heading level 1&lt;/h1&gt;\n...                         ...\n###### Heading level 6      &lt;h6&gt; Heading level 6&lt;/h6&gt;\n</code></pre> <p> or <pre><code>Markdown                    HTML\nHeading level 1             &lt;h1&gt; Heading level 1&lt;/h1&gt;\n===============\n\nHeading level 2             &lt;h2&gt; Heading level 1&lt;/h2&gt;\n---------------             \n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#paragraphs","title":"Paragraphs <p> A blank line can create a paragraph betwen some lines. <pre><code>Markdown\nI really like using Markdown.\n\nI think I'll use it from now on.\n--------------------------------\nHTML\n&lt;p&gt;I really like using Markdown.&lt;/p&gt;\n\n&lt;p&gt;I think I'll use it from now on.&lt;/p&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#line-breaks","title":"Line Breaks <p> Create a line break with ending the first line with two or more spaces and press return. <pre><code>Markdown\nFirst Line  \nSecond Line\n\nHTML\n&lt;p&gt;First Line&lt;br /&gt;\nSecond Line&lt;/p&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#bold","title":"Bold <pre><code>Markdown\n**bold text**\n__bold text__\n\nHTML \n&lt;strong&gt;bold text&lt;/strong&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#italics","title":"Italics <pre><code>Markdown\n*Italic text*\n_Italic text_\n\nHTML\n&lt;em&gt;Italic text&lt;/em&gt;\n</code></pre> <p> Combine bold and italic syntax to create bold and italic text.","text":""},{"location":"CS/Learn%20CS/Markdown/#blockquotes","title":"Blockquotes <p> Including multi-paragraphs, and blockquotes inside blockquotes. You can also add other markdown elements into blockquotes, but you'll need some experiments.  <p>This is a blockquote. <p>This is second para.  <p>This is nested blockquotes.   <pre><code>Mardown\n&gt;This is a blockquote.\n&gt;\n&gt;This is second para.\n&gt;&gt;This is nested blockquotes.\n\nHTML\n&lt;blockquote&gt;\n    &lt;p&gt;This is a blockquote.&lt;/p&gt;\n    &lt;p&gt;This is second para.&lt;/p&gt;\n    &lt;blockquote&gt;\n        &lt;p&gt;This is nested blockquotes.&lt;/p&gt;\n    &lt;/blockquote&gt;\n&lt;/blockquote&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#lists","title":"Lists","text":""},{"location":"CS/Learn%20CS/Markdown/#ordered-lists","title":"Ordered Lists <p> <ol> <li>This is an</li> <li>ordered list.</li> <li>In markdown the order of </li> <li>the number in front doesn't matter.</li> </ol> </p> <p> There is a small bug, when you are trying to set the font for the text, the ordered list doesn't work very smoothly. The number's don't show as they shoul, nor does the hyperlinks. <ol> <li>You need to change the font <li>in the ordered list.  <p> Also, you can nest the list items by four spaces or a tab. <pre><code>Markdown\n1.First Item\n1.Second Item\n    3.A nesting orderded list.\n    6.Like I said, numbers in front doesn't matter.\n1.Third Item\n\nHTML\n&lt;ol&gt;\n    &lt;li&gt;First Item&lt;/li&gt;\n    &lt;li&gt;Second Item&lt;/li&gt;\n        &lt;ol&gt;\n            &lt;li&gt;A nesting orderded list.&lt;/li&gt;\n            &lt;li&gt;Like I said, numbers in front doesn't matter.&lt;/li&gt;\n        &lt;/ol&gt;\n    &lt;li&gt;Third Item&lt;/li&gt;\n&lt;/ol&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#unordered-lists","title":"Unordered Lists <p> Unordered lists can be created by  <ul> <li>adding dashes (-),  <li>asterisks(*),  <li>or plus signs(+) in front of the line items.  <p> The unordered list can also be nested by adding tabs in front of the list. <pre><code>Markdown\n- First Line\n- Second Line\n    - The Nested Line\n- Third Line\n\nHTML\n&lt;ul&gt;\n    &lt;li&gt;First Line&lt;/li&gt;\n    &lt;li&gt;Second Line&lt;/li&gt;\n        &lt;ul&gt;\n            &lt;li&gt;The nested line&lt;/li&gt;\n        &lt;/ul&gt;\n    &lt;li&gt;Third Line\n&lt;/ul&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#adding-elements-in-lists","title":"Adding Elements in Lists <p> You can add other elements to a list with an extra tab in front of the elements. <p> e.g. two tabs in front of a code (code normally need one tab)","text":""},{"location":"CS/Learn%20CS/Markdown/#code","title":"Code <p> When you want to denote a word or phrase as a code, enclose the phrase and code in <code>tick marks</code> (`). <pre><code>Markdown\nThis is the word for `code`.\n\nHTML\nThis is the word for &lt;code&gt;code&lt;/code&gt;.\n</code></pre> <p> You can also escape tick marks with double tick marks when your code contains tick marks. <pre><code>``This is a code containing `tick marks`.``\n</code></pre> <p> You can also write code blocks when you add tabs to every line. <pre><code>public static main void(String[] args){\n    System.out.println(\"Hello world\")\n}\n\nHTML\n&lt;pre&gt;\n    &lt;code&gt;\n        &amp;lt;public static main void(String[] args){&amp;gt;\n            &amp;lt;System.out.println(\"Hello world\")&amp;gt;\n        &amp;lt;}&amp;gt;\n    &lt;/code&gt;\n&lt;/pre&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#horizontal-rules","title":"Horizontal Rules <p> Sometimes you want a horizontal line to seperate the contents you can add three  <p>dashes(---)  <p>asteriks(***)  <p>underscores(___) <p> to creat the horizontal line. Or in HTML fashion: <code>&lt;hr /&gt;</code> </p>","text":""},{"location":"CS/Learn%20CS/Markdown/#links","title":"Links <p> You can add titles to your links by adding the title behind the link seperated by a space and surrounded by the quotation marks (\"\"). <pre><code>Markdown\nUse [Duck Duck Go](https://duckduckgo.com \"My favourite search engine\")\n\nHTML\n&lt;p&gt; Use &lt;a href=\"https://duckduckgo.com\" title=\"My favourite search engine\"&gt;Duck Duck Go&lt;/a&gt;. &lt;/p&gt;\n</code></pre> <p> Also you can turn a URL or an email address into a link simply by enclosing it in angle brackes. <p>12112618@mail.sustech.edu.cn</p> <pre><code>&lt;12112618@mail.sustech.edu.cn&gt;\n</code></pre> <p> You can still format the links using the normal bold and italic format. <p> You can also write Reference-style Links <p> The first part of the reference-style link is the inline part, and is formatted with two sets of brackets.(You can add spaces between the two sets of brackets, but it's a bit wierd.) <p>reference-style link</p> <pre><code>[reference-styale link][1]\n[1]:&lt;https://google.com&gt; \"test with google\"\n</code></pre> <p> The title you want to give to the link is at the back of the web link, surrounded by parentheses or quotation marks.","text":""},{"location":"CS/Learn%20CS/Markdown/#images","title":"Images <p> To be honest, I prefer the HTML notation for the Images, because it's just much more easier to control their sizes and characters. <p></p> <pre><code>Markdown \n![The fat logo](./fatLogo.png \"a fat logo of the blog\")\n\nHTML\n&lt;img src=\"./fatLogo.png\" alt=\"the fat logo!\" title=\"a fat logo for the blog\" width=200 /&gt;\n</code></pre> <p> Also, mkdocs seems to have different ideas about the location of the images and tries to modify it by adding a thing in the front, which is super weird.","text":""},{"location":"CS/Learn%20CS/Markdown/#escaping-characters","title":"Escaping Characters <p> To escape the characters, you just need to add a backslash () in front ofthe character you want to escape.","text":""},{"location":"CS/Learn%20CS/Markdown/#extended-syntax","title":"Extended Syntax <p> Extended syntax are created from the superset of the basic syntax, to add new features to the already powerful Markdown files.","text":""},{"location":"CS/Learn%20CS/Markdown/#tables","title":"Tables <p> Tables are added with three or more hyphens (---) to create each column's header, and use pipes (|) to separate each column. Pipes at either end of the table are added optionally. <p> Also the size of the cell don't actually matter. <pre><code>Mardown\n| Syntax     | Description |\n|:-----------|------------:|\n| Header     | Title       |\n| Paragraph  | Text        |\n\nHTML\n&lt;table&gt;\n    &lt;thead&gt;\n        &lt;tr class=\"header\"&gt;\n            &lt;th&gt;Syntax&lt;/th&gt;\n            &lt;th&gt;Description&lt;/th&gt;\n        &lt;/tr&gt;\n    &lt;/thead&gt;\n    &lt;tbody&gt;\n        &lt;tr class=\"odd\"&gt;\n            &lt;td&gt;Header&lt;/td&gt;\n            &lt;td&gt;Title&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr class=\"even\"&gt;\n            &lt;td&gt;Paragraph&lt;/td&gt;\n            &lt;td&gt;Text&lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/tbody&gt;\n&lt;/table&gt;\n</code></pre> <p> You can set the alignment of the text inside the column by adding a colon (:) to the left, right, or on both sides of the hyphens (---). With HTML, you can add a CSS style to each table element. <pre><code>&lt;td style=\"text-align: left;\"&gt;Header&lt;/td&gt;\n</code></pre>    Syntax Description     Header Title   Paragraph Text    <p> You can do all sorts of formating inside the tables. <p> If you want to escape the pipe (|) character in a table, you can use its HTML character code (<code>&amp;#124;</code>).","text":""},{"location":"CS/Learn%20CS/Markdown/#fenced-code-blocks","title":"Fenced Code Blocks <p> You can create a fenced code block by using three tick marks(```) or three tildes (~~~). <pre><code>Markdown\n\\```\n{\n    The code here\n}\n\\```\n\nHTML\n&lt;pre&gt;\n    &lt;code&gt;\n        {\n            &amp;quot; The code here\n        }\n    &lt;/code&gt;\n&lt;/pre&gt;\n</code></pre> <p> You can add different colour highlighting according to the language by simply writing the language's name by the first three tick marks. <pre><code>```HTML\n```\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#footnotes","title":"Footnotes <p> To create a footnote reference, add a caret and an identifier inside brackets ([^1]). The Identifiers can be numbers or words, but they can't contain any space or tabs. The identifiers only correlate the footnote reference with the footnote itself. In the output, the footnotes are numbered sequentially. <p> Add the footnote using another caret and identifier inside brackets with a colon and text (<code>[^1]: One footnote.</code>). You can put the footnotes anywhere except in lists, blocks, quotes and tables. <pre><code>Markdown\nHere's a simple footnote,[^1] and another longer one.[^a_longer_footnote]\n\n[^1]: The first smaller footnote.\n\n[^a_longer_footnote]: This is a longer footnode and you can do lots of things.\n    You can add paragraphs to your footnote by indenting them.\n    `{can even add a code}`\n    You can add as many paragraphs as you like\n\n\nHTML\n&lt;p&gt;\n    Here's a simple footnote,&lt;a href=\"#fn1\" class=\"footnote-ref\" id=\"fnref1\"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; and another longer one.&lt;a href=\"#fn2\" class=\"footnote-ref\" id=\"fnref2\"&gt;&lt;sup&gt;a_longer_footnote&lt;/sup&gt;&lt;/a&gt;\n&lt;/p&gt;\n&lt;section class=\"footnotes\"&gt;\n    &lt;hr /&gt;\n    &lt;ol&gt;\n        &lt;li id=\"fn1\"&gt;&lt;p&gt;The first smaller footnote.&lt;a href=\"#fnref1\" class=\"footnote-back\"&gt; &lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n        &lt;li id=\"fn2\"&gt;\n            &lt;p&gt;The first smaller footnote.&lt;/p&gt;\n            &lt;p&gt;You can add paragraphs to your footnote by indenting them.&lt;/p&gt;\n            &lt;p&gt;&lt;code&gt;{can even add a code}&lt;/code&gt;&lt;/p&gt;\n            &lt;p&gt;You can add as many paragraphs as you like\n                &lt;a href=\"#fnref2\" class=\"footnote-back\"&gt; &lt;/a&gt;\n            &lt;/p&gt;\n        &lt;/li&gt;\n    &lt;/ol&gt;\n&lt;/section&gt;\n</code></pre> <p>     Here's a simple footnote,<sup>1</sup> and another longer one.<sup>a_longer_footnote</sup> </p> <p> The markdown notations doesn't seem to work, so I used the HTML ones.","text":""},{"location":"CS/Learn%20CS/Markdown/#heading-ids","title":"Heading IDs <p> You can custom your heading's id by enclosing the custom ID in curly braces on the same line as the heading. <pre><code>Markdown\n### The Great Heading {#custom-id}\n\nHTML\n&lt;h3 id=\"custom-id\"&gt;The Great Heading&lt;/h3&gt;\n</code></pre> <p> You can create a link to your heading by creating a standard link with the number sign (#) followed by the custom heading ID. But sadly, the markdown notation still doesn't work, I wonder... <pre><code>Markdown\n[Heading IDs](#heading-ids)\n\nHTML\n&lt;a href=\"#heading-ids\"&gt;Heading IDs&lt;/a&gt;\n</code></pre>","text":""},{"location":"CS/Learn%20CS/Markdown/#definition-lists","title":"Definition Lists <pre><code>Markdown\nFirst Term\n: This is the definition of the first term.\n\nSecond Term\n: This is the first definition of the second term.\n: This is another definition of the second term.\n\n\nHTML\n&lt;dl&gt;\n    &lt;dt&gt;First Term&lt;/dt&gt;\n    &lt;dd&gt;This is the definition of the first term.&lt;/dd&gt;\n    &lt;dt&gt;Second Term&lt;/dt&gt;\n    &lt;dd&gt;This is the first definition of the second term.&lt;/dd&gt;\n    &lt;dd&gt;This is another definition of the second term.&lt;/dd&gt;\n&lt;/dl&gt;\n</code></pre>  First Term This is the definition of the first term. Second Term This is the first definition of the second term. This is another definition of the second term.  <p> No surprise that the markdown syntax still doesn't work. Consider this as a great opportunity to learn HTML (LOL).","text":""},{"location":"CS/Learn%20CS/Markdown/#srikethrough","title":"Srikethrough <p> ~~Strike through~~ the words by adding two tilde symbols (~~) on both sides of the words. But it seems that the strikethrough don't work with mkdocs.","text":""},{"location":"CS/Learn%20CS/Markdown/#task-lists","title":"Task Lists <p> Task lists can be created with a dash line (-) and brackets with a space ([ ]). If you finished the task, then add a x in the brackets ([x]). <pre><code>Markdown\n- [ ] Write some Markdown files\n- [ ] Upload it to the website\n</code></pre>   <ol> <li><p>The first smaller footnote. </p></li> <li> <p>The first smaller footnote.</p> <p>You can add paragraphs to your footnote by indenting them.</p> <p><code>{can even add a code}</code></p> <p>You can add as many paragraphs as you like                   </p> </li> </ol>","text":""},{"location":"CS/Learn%20CS/R/","title":"Learning R","text":""},{"location":"CS/Learn%20CS/R/#basic-operators-and-functions","title":"Basic operators and functions <p><code>%%</code> :   mod <code>%/%</code> :   floor a/b <p><code>sort()</code> :   return an ascending sorted vector <code>rev()</code> :  reverse the elements in the vectorx[] <p> Numbers in R are usually seemed as double, unless pre-specified as integer by adding 'L' at the back.","text":""},{"location":"CS/Projects/","title":"Index","text":"<p> This page includes all the computer science related projects I have done in the past few years. Some of them might be written when the projects were finished, some might be written during the learning and writing process. All of them brought me a lot of knowledge and fun in the past few years. </p>"},{"location":"CS/Projects/ChessKing/","title":"My First Project - ChessKing","text":"<p> <p></p> <p> ChessKing was a Java project for the SUSTech course CS102A in 2022 Spring. Created by me and LittleEtx(Li Tian) with great passion.","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#the-beginning","title":"The Beginning <p> For people studying in ShenZhen, the spring of 2022 was very unique, especially when you were not living in ShenZhen during that time. Unluckly, me and LittleEtx were all living in GuangZhou. Because of the pandemic, we all had to stay in our home and take online classes everyday. Which was not very good, but I still found it had some advantages. <p> Especially when you are learning Computer Science. For me, computer science is a completely new subject and I was both excited and scared to learn CS102A. The Java class was known as the \"Freshmen Killer\" (together with Linear Algebra), and lots of students found it super hard and said it's learning process is \"torture\". Java classes will have a unique project every year and it's usually some kind of games. For exemple, the Java project for 2021 autumn is Reversi  <p> Luckly for me, my room mate LittleEtx is a total geek, and learning Java to him is like drinking water. So I chose the same class with him and stuck with him for the whole semester. Also, I found a fantastic book called Head First Java, which helped me a lot. Since I don't need to \"go\" to school, I spent most of my free time reading this book and learning Java. <p> After a few weeks, my Java programming skills grew and I found myself happily learning more Java than I expected.","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#the-project","title":"The Project <p> After the midterm exam week, our teacher finally announced the project this semester, which is Chess. The Chess includes a lot of rules and requirements for us to fulfill, so we started to prepare for the project on April 12th. When we created our first git.","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#git","title":"Git <p> Git was a new thing to both of us, because we never used version control before. It was LittleEtx's idea to use Git and he built a repository on GitHub. It was a bit confusing to use (at least for me) at first because of all the pull, commit, and push actions. But luckily it's year 2022 and we have GitHub desktop and IntelliJ IDEA, which made things a lot moer easier than using the terminal for all the actions. I'm proud to say that I am quite used to using version controls now (BTW this blog is also under git's version control).","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#fxgl","title":"FXGL <p> The next thing was finding a good engine for our game. We have no idea about ui design with Java, and we need a ui for our game. So we search on the internet and found JavaFX an open source ui tool for Java. We searched on bilibili and found a set of videos teaching us how to write games using an engine called FXGL. FXGL is a very interesting and powerful game engine based on JavaFX. It allows us to design different scenes and stages for the game and can add entities in a very smart and efficient way. It requires some learning but we are happy to do it, I even made my own basic tank game as I'm learning!","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#ui-design","title":"UI Design <p> In the whole project, our work is pretty seperated. LittleEtx is responsable for designing the basic logic of the game, and I am responsable for all the UI, in other words, all the things you can see in the game. Including the buttons (and their interactions), chess, backgrounds and so on.","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#css","title":"CSS <p> I need a way to customize all the buttons and HBoxes and VBoxes and so on. So I Googled and found CSS, the language used to style HTML document, but is also supported by JavaFX. I spent a lot of time learning how to change the style of the buttons and adding different images and colours to the backgrounds, and at the end of the project, I am very proud to say that 2.9% of the whole project's language is CSS, and is all written by me!  <p></p>","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#themes-for-the-game","title":"Themes for the Game <p> The one function I spent most time on was the place where you can chose your theme. You can choose your own avatar, background picture, chess board colours and the skin for your chess. Which will be automatically stored with your player account. <p></p> <p> Avatars are chosen from some of our favourite art works, including games and animations. So are some of the background music. If you want to learn more about our hobbies, you can read the README.md for the repository, where we introduced our likings with love and care.","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#a-diy-chess-skin","title":"A DIY Chess Skin <p> Later the teachers and teaching assistants of the course provided us with a demo (written in swing), which contains a very common chess skin. At first, we think it's very convinient, so we just used the pictures inside the demo (and that's what most of the students do). But later, we think the original chess skin is not catchy and can't fulfill our wish that this is a complete and stylish game of our own. So I drew a set of skin for our chess, using my favourite pixel style. It turned out to be very similar to Dead Cells, but I'm a huge fan of the game so it's fine. <p></p>","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#the-mvc-model","title":"The MVC Model <p> When we finished making the whole game, we found out that we actually were making something that fitted the MVC model, which in simple words, is the seperation of the things the user can control from the basic logic of the game. As I learnt more about MVVM (the Apple swift structure for an app), I started to notice that there are still some things we could improve to achieve a better structure, but I'm still very pleased that we made some sign of a MVC model game.","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#the-show","title":"The Show","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#dream","title":"Dream <p> From the beginning of our long work, our dream had been to make a game that is whole and complete. Which means that it should at least fulfill all the requirements of a normal chess game, have a menu and players have individule savings. Also, since it's a computer game, we wish to have strong AIs that can torture human players when tey are boring. That's why, when most of our classmates are using the teacher's demo as a template, we started to write the whole game from scratch.","text":"","tags":["Java","Games"]},{"location":"CS/Projects/ChessKing/#presentation","title":"Presentation <p> Naturally, our hard work was approved by our teachers. Not only did we get a high grade, we were also invited to present our work in the big class. We consider it to be a great opportunity to share our happiness with all our classmates.  <p> It was at this time, that I learned how to write Markdown files. I wrote a README file for our repository, and another file for our presentation. The presentation file contatins all the knowledges we had learnt during this wonderful experience. <p> I'm so happy to see all the interested and astonished faces of my classmates when we did our presentation. After the class, they are all chatting in the chat group for our game. We feel so happy that our work is admitted by others. It's a wonderful learning experience!","text":"","tags":["Java","Games"]},{"location":"CS/Projects/Projects/","title":"Projects","text":"<p> This page includes all the computer science related projects I have done in the past few years. Some of them might be written when the projects were finished, some might be written during the learning and writing process. All of them brought me a lot of knowledge and fun in the past few years. </p>","tags":["Java","Games"]},{"location":"CS/Projects/Projects/#my-first-project-chessking","title":"My First Project - ChessKing","text":"<p>ChessKing was a Java project for the SUSTech course CS102A in 2022 Spring.","tags":["Java","Games"]},{"location":"Learning/","title":"Biology!!!","text":"<p> Although I have chosen my major, I'm still super interested in a lot of other subjects such as chemistry, physics and math. Some art related subjects are also very interesting. I read a lot of books in my spare time, so I might also put some reading responses on here too. Wait for them ~ <p> Click on the files on the left side to learn more! </p>"},{"location":"Learning/Chemistry/Experiments/","title":"Chemistry Experiments","text":""},{"location":"Learning/Physics/fly_by_night/","title":"FLy by Night Physics Notes","text":""},{"location":"Learning/Physics/fly_by_night/#dimensional-analysis","title":"Dimensional Analysis","text":""},{"location":"Learning/Physics/fly_by_night/#pendulum-period","title":"Pendulum Period","text":""},{"location":"Learning/Physics/fly_by_night/#simple-dimensional-analysis","title":"Simple Dimensional Analysis","text":"<p>Time \\(T\\) have the dimension of time \\([T] = T\\). If we want ot express time in terms of length \\(l\\) and acceleration \\(a\\), with \\([l] = L\\) and \\([a] = L/T^2\\). Thus the period must be: </p> \\[ T \\sim \\sqrt{l/a} \\] <p>The exact equation should be \\(T = 2 \\pi \\sqrt{l/a}\\). The \\(2 \\pi\\) can be determined by experiment. </p> <p>Or if we consider angular speed and with energy conservation equation, we can get the direct equation for \\(\\omega\\) and \\(T\\):</p> \\[ E = \\frac{1}{2} m \\dot{\\theta}^2 + m g l (1 - \\cos \\theta) \\simeq \\frac{1}{2} m \\dot \\theta^2 + \\frac{1}{2} m g l \\theta^2 \\] <p>The \\(\\simeq\\) was obtained from the small angle approximation (with taylor series). Plug in \\(\\theta = \\theta_0 \\cos{\\omega t}\\), we get:</p> \\[ E = \\frac{1}{2} m \\omega^2 \\theta_0^2 \\sin^2{\\omega t} + \\frac{1}{2} m g l \\theta_0^2 \\cos^2{\\omega t} \\] <p>In order for \\(E\\) to be a constant, \\(m \\omega^2 \\theta_0^2 = m g l \\theta_0^2\\). Thus \\(\\omega = \\sqrt{g/l}\\), and \\(T = 2 \\pi / \\omega = 2 \\pi \\sqrt{l/g}\\).</p>"},{"location":"Learning/Physics/Quantum/Basics/","title":"Quantum Mechanics","text":""},{"location":"Learning/Physics/Quantum/Basics/#probability-rules","title":"Probability Rules","text":"<p>For a wave function \\(\\Psi(x,t)\\), we can solve it with the Schrodinger Equation:</p> \\[ i\\hbar \\frac{\\partial \\Psi}{\\partial t} = - \\frac{\\hbar^2}{2m} \\frac{\\partial^2 \\Psi}{\\partial t^2} + V \\Psi \\] <p>Where \\(V\\) is the potential energy of the system. \\(\\hbar\\) is the reduced Planck constant, \\(\\hbar = \\frac{h}{2\\pi} = 1.054572\\times 10^{-34} \\text{J s}\\).</p> <p>The wave function \\(\\Psi\\) is a complex function, and the probability of finding a particle at \\(x\\) is \\(|\\Psi(x,t)|^2\\). The probability of finding a particle in the range \\([a,b]\\) is: </p> \\[ P(a \\leq x \\leq b) = \\int_a^b |\\Psi(x,t)|^2 dx \\] <p>After a measurement, the wave function instantly collapses to the measured state. With time, the wave function evolves back to a widely distributed state. The wave function can be solved with the Schrodinger Equation.</p> <p>An example for calculating with the probability density. (I'm not very smart about physics, so this example in my mind, is so smart and witty.)</p> <p>Suppose I drop a rock off a cliff of height \\(h\\). As it falls, I snap a million photographs, at random intervals. On each picture I measure the distance the rock has fallen. Question: What is the average of all the distances? i.e. what is the time average of the distance traveled?</p> <p>Solution:</p> \\[ x(t) = \\frac{1}{2}gt^2 \\] <p>The velocity is $$ v(t) = \\frac{dx}{dt} = gt $$ and the total flight times is </p> \\[T = \\sqrt{\\frac{2h}{g}}\\] <p>The probability of the camera flashing is $ dt / T$ (if the camera flashes for a short period of time \\(dt\\)). Thus the length traveled in this photograph is:</p> \\[ \\frac{dt}{T} = {dt}\\cdot \\sqrt{\\frac{g}{2h}} = \\frac{dx}{gt}\\cdot \\sqrt{\\frac{g}{2h}} = \\frac{1}{2\\sqrt{hx}} dx \\] <p>So the probability density is </p> \\[ \\rho(x) = \\frac{1}{2\\sqrt{hx}} \\] <p>The average distance is </p> \\[ \\langle x \\rangle = \\int_0^h x \\rho(x) dx = \\int_0^h x\\frac{1}{2\\sqrt{hx}} dx = \\frac{1}{2 \\sqrt{h}} (\\frac{2}{3} x^{3/2}) \\Big|_0^h = \\frac{h}{3} \\] <p>Because the wave function have a relationship with probability, the wave function must be normalized. The normalization condition is:</p> \\[ \\int_{-\\infty}^{\\infty} |\\Psi(x,t)|^2 dx = 1 \\] <p>The normalization condition with a constant (complex constant) \\(A\\) is conserved . That is to say, the Schrodinger Equation has the remarkable property that it automatically preserves the normalization of the wave function. That is to say, probability is independent of time. Which can be proved.</p> \\[\\frac{d}{dt} \\int_{-\\infty}^{\\infty} | \\Psi(x,t) |^2 dx = \\int_{-\\infty}^{\\infty} \\frac{\\partial }{\\partial t} | \\Psi(x,t) |^2 dx\\] <p>Because the integral is independent of \\(t\\), we can move the derivative inside the integral. And we can use the Schrodinger Equation to replace the derivative. Before that, by the product rule:</p> \\[\\frac{\\partial}{\\partial t} | \\Psi |^2 = \\frac{\\partial}{\\partial t}(\\Psi^* \\Psi) = \\frac{\\partial }{\\partial t} \\Psi^* \\Psi + \\Psi^* \\frac{\\partial }{\\partial t} \\Psi\\] <p>Thus with the Schrodinger Equation:</p> \\[ \\frac{\\partial}{\\partial t} | \\Psi |^2 = \\frac{i \\hbar}{2m} (\\Psi^* \\frac{\\partial^2 \\Psi}{\\partial x^2}  + \\frac{\\partial^2 \\Psi^* }{\\partial x^2} \\Psi) = \\frac{\\partial }{\\partial x} \\Big[\\frac{i \\hbar}{2m} \\Big( \\Psi^* \\frac{\\partial \\Psi}{\\partial x} - \\frac{\\partial \\Psi^*}{\\partial x} \\Psi \\Big) \\Big]\\] <p>So the integral:</p> \\[\\frac{d}{dt} \\int_{-\\infty}^{\\infty} | \\Psi(x,t) |^2 dx \\] \\[ = \\int_{-\\infty}^{\\infty} \\frac{\\partial }{\\partial x} \\Big[\\frac{i \\hbar}{2m} \\Big( \\Psi^* \\frac{\\partial \\Psi}{\\partial x} - \\frac{\\partial \\Psi^*}{\\partial x} \\Psi \\Big) \\Big] dx \\] \\[ = \\frac{i \\hbar}{2m} \\Big( \\Psi^* \\frac{\\partial \\Psi}{\\partial x} - \\frac{\\partial \\Psi^*}{\\partial x} \\Psi \\Big) \\Big|_{-\\infty}^{\\infty} = 0 \\] <p>Because the wave function must be zero at \\(-\\infty\\) and \\(\\infty\\). Thus the probability is independent of time. QED</p> <p>Interestingly, problem 1.17 in the book gave an example of a particle that is not stable, and have a half life. In that case, the probability function \\(P(t)\\) becomes dependent on time. We can describe this by adding an imaginary part to \\(V\\).</p> \\[ V = V_0 - i \\frac{\\hbar}{2\\tau} \\] <p>Where \\(\\tau\\) is the half life of the particle. The imaginary part of \\(V\\) is called the decay term. </p> <p>In the quantum mechanic's world, particles don't follow the normal laws of mechanics, but interestingly there is the Ehrenfest's theorem. Which states that the expectation values obey the classical laws.</p> \\[ \\langle x \\rangle = \\int_{-\\infty}^{\\infty} x | \\Psi (x,t) |^2 dx \\] \\[ \\langle p \\rangle = m \\frac{d \\langle x \\rangle}{dt} = \\int_{-\\infty}^{\\infty} \\Psi^* \\Big( -i \\hbar \\frac{\\partial \\Psi}{\\partial x} \\Big) dx \\] <p>Here we also introduces another new operator, for any quantity related to \\(x\\) and \\(p\\), \\(Q(x,p)\\), the expectation of this quantity is:</p> \\[ \\langle Q \\rangle = \\int_{-\\infty}^{\\infty} \\Psi^* Q(x, -i \\hbar \\frac{\\partial}{\\partial x}) \\Psi dx \\] <p>For a given particle, it is impossible to know it's position and momentum at the same time. This is called the Heisenberg Uncertainty Principle. The uncertainty principle is a direct consequence of the wave nature of matter. The uncertainty principle is:</p> \\[ \\sigma_x \\sigma_p \\geq \\frac{\\hbar}{2} \\] <p>Where \\(\\sigma_x\\) is the standard deviation of \\(x\\), and \\(\\sigma_p\\) is the standard deviation of \\(p\\).</p>"},{"location":"Life/","title":"Biology!!!","text":"<p>To see the world, things dangerous to come to, to see behind walls, draw closer, to find each other and to feel. That is the purpose of life. <p> - The Secret Life of Walter Mitty</p> <p> Click on the files on the left side to learn more! </p>"},{"location":"Life/Books/TAOS/","title":"The Art of Statistics","text":""},{"location":"Life/Books/TAOS/#me-and-the-book","title":"Me and the Book <p> The Art of Statistics is a book by English statistician David Spiegelhalter (maybe Sir D.J.Spiegelhalter). In the summer holidays of 2022, I got into the fields of bioinformatics and start doing some basic RNA sequencing, when we analyse the data of the RNA sequencing, we use things like Principle Component Analysis and p-value to determine the significance between our experiment group and our control group. The statistics part realy confused me because I don't have the background knowledge, and are definetely not familiar with things like normal distribution or linear regression (although I'm pretty good at linear algebra and understood PCA and SVD quite easily). Just when I was struggling with this problem, I came across this book while walking around a bookstore (One Page in GZ book center to be precise). I didn't buy it at the moment, but it lingered in my brain. After seeing the book again online, I decided to buy it. <p> Well, then I fell in love with it and finished the book in two and a half weeks. The fact that I love the book doesn't necessarily mean that this book is perfect. In fact, I think this book is far and far away from pefect, with (I don't know if my english is good enough to judge) some grammar issues (or it might be my own problem), and places where the authour just explain things in a very messy and unclear way (like the linear regression part). <p> But still, it's a very great introduction level book. It tells you the basic knowledge you need and how people should think about a problem in a statistiacally correct way. <p> All in all, this is a pretty great book.","text":""},{"location":"Life/Books/TAOS/#chapter-0-introduction","title":"Chapter 0 Introduction <p> With a stunning case-study about the Harold Shipman murder, the author led us into a beautiful world of statistics. Using data to find patterns. He also introduced the most important workflow for a statistician, the Problem-Plan-Data-Analysis-Conclusion (PPDAC) workflow.","text":""},{"location":"Life/Books/TAOS/#chapter-1-getting-things-in-proportion-categorical-data-and-percentages","title":"Chapter 1 Getting Things in Proportion: Categorical Data and Percentages <p> In this chapter, the author introduced the very basic idea of a binary variable, sets of which can be summarized as proportions. Different ways of showing your data might lead to different emotional impact on your audiences. We need to be very careful on how we express our findings so that our audiences won't be misled.","text":""},{"location":"Life/Books/TAOS/#chapter-2-summarizing-and-communicating-numbers-lots-of-numbers","title":"Chapter 2 Summarizing and Communicating Numbers. Lots of Numbers. <p> When you have a lot of data, you need a better way of summarizing it and communicating it. The well-known mean median and mode are just easy ways to describe the data. We can also draw strip-charts, box-and-whisker plots or histograms. While we are exploring data, we want to search for a common trend, that is, finding factors that explains the overall variation.","text":""},{"location":"Life/Books/TAOS/#chapter-3-why-are-we-looking-at-data-anyway-populations-and-measurement","title":"Chapter 3 Why Are We Looking at Data Anyway? Populations and Measurement. <p> We perform our studies in order to get a more general understanding of the whole population. That's why we need to go from our data to our study sample and study population, and finally to our target population.","text":""},{"location":"Life/Books/TAOS/#chapter-4-what-causes-what","title":"Chapter 4 What Causes What? <p> This is one of my favourite chapters where the author talks about how do we determine the cause and effect relationship between two events. The apophenia nature of human tends to lead us to finding causation in two events just based on their correlation. This chapter also inspired me to buy another book, which is talking about causations.","text":""},{"location":"Life/Books/TAOS/#chapter-5-modelling-relationships-using-regression","title":"Chapter 5 Modelling Relationships Using Regression <p> Building statistical models are very important for analysis. This is also something we learnt during high school. But we were just remembering the equations by then, not caring the deeper knowledge behind them. But this is not a very good chapter if you want to learn about regression models. Because although the author explains the concepts in a very clear way, it lacks mathematical explaination, making all the regression models very abstract. So I guess google will help you a lot on learning about regression modelling.","text":""},{"location":"Life/Books/TAOS/#chapter-6-algorithms-analytics-and-prediction","title":"Chapter 6 Algorithms, Analytics and Prediction <p> What we learnt in high school is that regression modelling is a way to find a general trend in our data points, and can also be used as a simple model to predict results. But in the real world, there are whole bunch of different algorithms in order to predict. From the most simple and elegant classification tree, to complicated and enormous machine learning, all methods can be used to predict the rate of survival for a passenger on the Titanic. And the simpler algorithm might work better than you think! The author also introduced how to compare different algorithms. It is so surprising that the 3 layered classification tree provided by the author actually works very well in predicting the results.","text":""},{"location":"Life/Books/TAOS/#chapter-7-how-sure-can-we-be-about-what-is-going-on-estimates-and-intervals","title":"Chapter 7 How Sure Can We Be About What Is Going On? Estimates and Intervals <p> We cannot be 100% sure about our prediction based on our statistics, but we have a margin error, which indicates where the true value might lie. In other words, we are 95% sure that the true value will lie between the margin of error, based on past experiences and bootstrapping. The percentages in this chapter is actually quite confusing, like the 95% doesn't imply that our prediction is 95% true.","text":""},{"location":"Life/Books/TAOS/#chapter-8-probability-the-language-of-uncertainty-and-variability","title":"Chapter 8 Probability - the Language of Uncertainty and Variability <p> Probability is a very amazing thing. It does not exist in the real world, it's just something human made up to try to explain the world. Like the coin wasn't born with a probability of 1/2 to land on heads or tails, we humans gave it this probability.","text":""},{"location":"Life/Books/TAOS/#chapter-9-putting-probability-and-statistics-together","title":"Chapter 9 Putting Probability and Statistics Together <p> This chapters combine bootstrapping, probability and statistics together to explain the concept of the margin of error.","text":""},{"location":"Life/Books/TAOS/#chapter-10-answering-questions-and-claiming-discoveries","title":"Chapter 10 Answering Questions and Claiming Discoveries <p> This is by far my most favourite chapter. Based on past experiences, we are able to calculate the probability of an event happening. And if the probability is super small, then we can consider this event as very significant. That is precisely where my interest p-value comes. It describes getting the same result if your hypothesis is not true and some event is just randomly happening. It's very simple and elegant value, and is also controversial, because it might lead to false discoveries. So there is also the Neyman-Pearson Theory, where we can set previously the size and power of the test based on the possibility of finding the null hypothesis true. So that we can get a more accurate p-value and set a reasonable sample number.","text":""},{"location":"Life/Books/TAOS/#chapter-11-learning-from-experience-the-bayesian-way","title":"Chapter 11 Learning from Experience the Bayesian way <p> This is a very interesting chapter, which talks about giving a former distribution to all the factors that might influence our experiment, and finally getting a score for our hypothesis, indicating it is true or not. This idea is very interesting, and I'm super interested in the math behind all of this. Sadly, the author stopped again at the basic concepts and basic maths.","text":""},{"location":"Life/Books/TAOS/#final-2-chapters","title":"Final 2 chapters <p> After all the statistical knowledge, the author introduced how things can go wrong on each step of the PPDAC workflow, and how can things go wrong while our results are delivered to the public. He also provided solutions to all the problems.","text":""}]}